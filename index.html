<!DOCTYPE html PUBLIC "-//IETF//DTD HTML 2.0//EN">

<!--

Copyright 1999-2002 Carnegie Mellon University.  
Portions Copyright 2002 Sun Microsystems, Inc.  
Portions Copyright 2002 Mitsubishi Electric Research Laboratories.
All Rights Reserved.  Use is subject to license terms.

See the file "license.terms" for information on usage and
redistribution of this file, and for a DISCLAIMER OF ALL 
WARRANTIES.

-->

<html>
<head>
  <title>Sphinx-4 - A speech recognizer written entirely in the
 Java(TM) programming language</title>
<STYLE TYPE="text/css">
     pre { font-size: medium; background: #f0f8ff; padding: 2mm; border-style: ridge ; color: teal}
     code {font-size: medium; color: teal}
     s4keyword { color: red; font-weight: bold }
</STYLE></head>

<body bgcolor="white">
  <center>
    <table bgcolor="#99CBFF" border="0" width="100%">
      <tbody>
        <tr>
	  <td align="center" width="100%">
	    <h1><i>Sphinx-4</i><br><font size="+1">
	    A speech recognizer written entirely in the 
	    Java<sup><font size="-1">TM</font></sup> 
	    programming language</font></h1>
	  </td>
        </tr>
      </tbody>
    </table>
  </center>
  <font face="Arial" size="2">

  <table border="0" width="100%">
    <tbody>
      <tr>
        <td bgcolor="#F0F8FF" valign="top" width="20%">
          <br>
	  <b><font>Sphinx-4 Links</font></b>
          <p>
	  <font size="-1">
	  SourceForge
	  <li><a href="http://sourceforge.net/projects/cmusphinx">Project Page</a>
          <li><a href="https://sourceforge.net/forum/?group_id=1094">Forums</a>
          <li><a href="http://sourceforge.net/project/showfiles.php?group_id=1904">Download</a>
          <li><a href="http://sourceforge.net/cvs/?group_id=1904">CVS Repository</a>
	  <p>
	  <a href="http://cmusphinx.org">CMU Sphinx</a>
	  </p>
	  <p>
	  <a href="http://cmusphinx.sourceforge.net/sphinx4/javadoc/index.html">Sphinx-4 Javadocs</a>
      </p>
      <hr>
      <b>ZipCity</b> -
      A demonstration of Sphinx-4 using Java Web Start technology. <a
          href="demo/sphinx/zipcity/README.html"> Read more</a> about
      the ZipCity demo, or <a href="zipcity/zipcity.jnlp"> Try it </a>. <p>
      <a href="zipcity/zipcity.jnlp"><img src="doc-files/zipcity.gif"/></a>
      <hr>
          <center><a href="http://www.sourceforge.net">
          <img src="http://sourceforge.net/sflogo.php?group_id=1904&amp;type=1"
          width="88" height="31" border="0" alt="SourceForge Logo"></a>
          <br>Hosted by SourceForge.net</center>
          </font></b></td>

      <td width="5%"><br>
      </td>

      <td valign="top"><br>
      <h3>General Information</h3>
      <ul>
        <li><a href="#what_is_sphinx4">Introduction</a></li>
        <li><a href="#capabilities">Capabilities</a></li>
        <li><a href="#speed_and_accuracy">Performance</a></li>
      </ul>

      <h3>Installation</h3>
      <ul>
        <li><a href="#download_and_install">Required Software</a></li>
        <li><a href="#source">Downloading Sphinx-4</a></li>
        <li><a href="#how_build">Building Sphinx-4</a></li>
	<li><a href="#create_javadocs">Creating Javadocs</a></li>
	<li><a href="#faq">Troubleshooting</a></li>
      </ul>

      <h3>Demos</h3>
      <ul>
	<li><a href="#demos">Demos</a></li>
      </ul>

      <h3>Sphinx-4 in Detail</h3>
      <ul>
	<li><a href="#sphinx_properties">Understanding Sphinx-4
        Configuration Management</a></li>
	<li><a href="#sphinx_instrumentation">Understanding Sphinx-4
        Instrumentation </a></li>
	<li><a href="javadoc/edu/cmu/sphinx/frontend/doc-files/FrontEndFAQ.html">Front End</a></li>
	    <ul>
	        <li><a href="javadoc/edu/cmu/sphinx/frontend/doc-files/FrontEndConfiguration.html">Configuration</a></li>
		<li><a href="javadoc/edu/cmu/sphinx/frontend/doc-files/FrontEndFAQ.html#create_cepstra">Creating spectrum/cepstrum</a></li>
		<li><a href="javadoc/edu/cmu/sphinx/frontend/doc-files/FrontEndFAQ.html#decode_cepstra">Decoding cepstra</a></li>
		<li><a href="javadoc/edu/cmu/sphinx/frontend/doc-files/FrontEndFAQ.html#enable_endpointer">Enabling the endpointer</a></li>
	    </ul>
	<li><a href="#batch_tests">Running the Regression Tests</a></li>
	<li><a href="#setup_test">Setting up a Regression Test</a>
	    <ul>
	       <li><a href="#batch_files">Batch Files</a>
	       <li><a href="#input_files">Input Audio/Cepstral Files</a>
	       <li><a href="#an4_walkthrough">Example: Setting up AN4 tests</a>
	    </ul>
	</li>
	<li><a href="#acoustic_models">Acoustic Model Package</a></li>
	<li><a href="#language_models">Creating Language Models</a></li>
	<li><a href="#bnf_grammars">BNF Style Grammars</a></li>
        <li><a href="#architecture_and_api1">Architecture and API</a></li>
	<li><a href="doc/ProgrammersGuide.html">Programmer's Guide</a></li>
      </ul>

      <p>
      <br>
      <font size="-1">
      <b>NOTE</b>: This page contains links to javadocs that need to be
      created. If the links are broken, you should either follow instructions 
      in <a href="#create_javadocs">Creating Javadocs</a>, or view this page
      online at <a href="http://cmusphinx.sourceforge.net/sphinx4/">
      http://cmusphinx.sourceforge.net/sphinx4/</a>.
      </font>

      <p>

      </td>
    </tr>
  </tbody>
</table>

<hr>

<h2>General Information about Sphinx-4</h2>
<ul>
  <li><a name="what_is_sphinx4"><b>Introduction</b></a>
      <p>Sphinx-4 is a state-of-the-art speech recognition system
	 written entirely in the Java<sup><font size="-1">TM</font></sup>
	 programming language.
         It was created via a joint collaboration between the Sphinx group
	 at Carnegie Mellon University, Sun Microsystems Laboratories,
	 Mitsubishi Electric Research Labs (MERL), and Hewlett Packard (HP),
	 with contributions from the University of California at Santa
         Cruz (UCSC) and the Massachusetts Institute of Technology
         (MIT).

      <p>Sphinx-4 started out as a port of Sphinx-3 to the
         Java(TM) programming language, but evolved into a recognizer
         designed to be much more flexible than Sphinx-3, thus
         becoming an excellent platform for speech research.
  </li>
  <br>&nbsp;
  <li><a name="capabilities"><b>Capabilities</b></a>

      <p>Live mode and batch mode speech recognizers, capable of recognizing
         discrete and continuous speech.

      <p>Generalized pluggable <a href="./javadoc/edu/cmu/sphinx/frontend/package-summary.html"><b>front end</b></a> 
         architecture.
         Includes pluggable implementations of
	 <a href="./javadoc/edu/cmu/sphinx/frontend/filter/Preemphasizer.html">preemphasis</a>,
	 <a href="./javadoc/edu/cmu/sphinx/frontend/window/RaisedCosineWindower.html">Hamming window</a>,
	 <a href="./javadoc/edu/cmu/sphinx/frontend/transform/DiscreteFourierTransform.html">FFT</a>,
	 <a href="./javadoc/edu/cmu/sphinx/frontend/frequencywarp/MelFrequencyFilterBank.html">Mel frequency filter bank</a>,
	 <a href="./javadoc/edu/cmu/sphinx/frontend/transform/DiscreteCosineTransform.html">discrete cosine transform</a>,
	 <a href="./javadoc/edu/cmu/sphinx/frontend/feature/BatchCMN.html">cepstral mean normalization</a>, and
	 <a href="./javadoc/edu/cmu/sphinx/frontend/feature/DeltasFeatureExtractor.html">feature extraction</a> of cepstra,
	 delta cepstra, double delta cepstra features.

      <p>Generalized pluggable <b>language model</b> architecture.  Includes
         pluggable language model support for
	 <a href="./javadoc/edu/cmu/sphinx/linguist/language/ngram/SimpleNGramModel.html">ASCII</a> and 
	 <a href="./javadoc/edu/cmu/sphinx/linguist/language/ngram/large/LargeTrigramModel.html">binary</a>
	 versions of unigram, bigram, trigram, 
	 <a href="./javadoc/edu/cmu/sphinx/jsapi/JSGFGrammar.html">Java Speech API Grammar Format (JSGF)</a>, and 
	 <a href="./javadoc/edu/cmu/sphinx/linguist/language/grammar/FSTGrammar.html">ARPA-format FST grammars</a>.  

      <p>Generalized <a href="./javadoc/edu/cmu/sphinx/linguist/acoustic/package-summary.html"><b>acoustic model</b></a> 
         architecture. Includes pluggable support for 
	 <a href="./javadoc/edu/cmu/sphinx/linguist/acoustic/tiedstate/Sphinx3Loader.html">Sphinx-3 acoustic models</a>.

      <p>Generalized <a href="./javadoc/edu/cmu/sphinx/decoder/search/package-summary.html"><b>search management</b></a>.
         Includes pluggable support for
	 <a href="./javadoc/edu/cmu/sphinx/decoder/search/SimpleBreadthFirstSearchManager.html">breadth first</a> and 
	 <a href="./javadoc/edu/cmu/sphinx/decoder/search/WordPruningBreadthFirstSearchManager.html">word pruning</a> searches.

      <p>Speech tools. Includes tools for 
         <a href="./javadoc/edu/cmu/sphinx/tools/audio/package-summary.html">displaying waveforms and spectrograms</a> and
	 <a href="./javadoc/edu/cmu/sphinx/tools/feature/package-summary.html">generating features from audio</a>.

      <p>
      (<b>NOTE:</b> The links in this section point to local files created by
      javadoc. If they are broken, please follow the instructions on 
      <a href="#create_javadocs">Creating Javadocs</a> to create these links.)
  </li>

  <br>&nbsp;
  <li><a name="speed_and_accuracy"><b>Performance</b></a>
      <p>Sphinx-4 is a very flexible system capable of performing many
         different types of recognition tasks.  As such, it is
         difficult to characterize the performance and accuracy of
         Sphinx-4 with just a few simple numbers such as speed and
         accuracy.  Instead, we regularly run regression tests on
         Sphinx-4 to determine how it performs under a variety of
         tasks.  These tasks and their latest results are as follows
         (each task is progressively more difficult than the previous
	 task):
      <ul>
          <li><a href="http://cmusphinx.sourceforge.net/IsolatedDigitsResults.html">
              Isolated Digits (TI46)</a>: Runs Sphinx-4 with pre-recorded
              test data to gather performance metrics for recognizing
              just one word at a time.  The vocabulary is merely the
              spoken digits from 0 through 9, with a single utterance
              containing just one digit.
	      <br><i>(TI46 refers to the "NIST CD-ROM Version of the Texas
	      Instruments-developed 46-Word Speaker-Dependent Isolated Word
	      Speech Database".)</i>
          </li>
	  <br>
          <li><a href="http://cmusphinx.sourceforge.net/ConnectedDigitsResults.html">
              Connected Digits (TIDIGITS)</a>: Extends the Isolated
              Digits test to recognize more than one word at a time
              (i.e., continuous speech).  The vocabulary is merely the
              spoken digits from 0 through 9, with a single utterance
              containing a sequence of digits.
	      <br><i>(TIDIGITS refers to the "NIST CD-ROM Version of the Texas
	      Instruments-developed Studio Quality Speaker-Independent
	      Connected-Digit Corpus".)</i>
          </li>
	  <br>
          <li><a href="http://cmusphinx.sourceforge.net/SmallVocabResults.html">
              Small Vocabulary (AN4)</a>: Extends the vocabulary
	      to approximately 100 words, with input data ranging
	      from speaking words as well as spelling words out
	      letter by letter.
          </li>
	  <br>
          <li><a href="http://cmusphinx.sourceforge.net/MediumVocabResults.html">
              Medium Vocabulary (RM1)</a>: Extends the vocabulary
	      to approximately 1000 words.
          </li>
	  <br>
          <li><a href="http://cmusphinx.sourceforge.net/LargeVocabResults.html">
              Large Vocabulary (HUB4)</a>: Extends the vocabulary
	      to approximately 64000 words.
          </li>
      </ul>
  </li>
</ul>

<hr>

<h2>Installation</h2>

<ul>

<li><a name="download_and_install"><b>Required Software</b></a>

      <p>Sphinx-4 has been built and tested on the Solaris<sup> <font
      size="-1">TM</font></sup> Operating Environment, Mac OS X, Linux
      and Win32 operating systems. Running, building, and testing 
      Sphinx-4 requires additional software. Before you start, 
      you will need the following software available on your machine.</p>

<ul>
  <li><b>Java 2 SDK, Standard Edition, v1.4</b> or better. 
      Go to <a href="http://java.sun.com">java.sun.com</a>,
      and select "J2SE". At the time of writing, the latest release
      version is 1.4.2, which is the one we recommend.
      </li>

  <br>
  <li><b>Ant 1.6.0</b> or better, available at <a
  href="http://ant.apache.org">ant.apache.org</a>. The site has a manual 
  with instructions on how to download, install, and use ant. 
  The gist of it, just to get started:
  <ul>
  <li> On <a href="http://ant.apache.org">ant.apache.org</a> click on
  "binary distributions" under "Download", on the left-hand side.
  </li>

  <li> Go to the title "Current release of ant", and select the
  archive file of your preference. The most common formats are
  "tar.gz" and "zip". Clicking on any of them should start downloading
  the file to your machine.
  </li>
  <li> Save the file locally, and extract the files from the
  archive. On Windows machines, clicking on the archive file should
  start "WinZip". On Unix/Linux machines, depending on which file you
  chose, you'll need to "unzip" or "gunzip" and subsequently "tar xf"
  the file.
  </li>
  <li> After extracting the files from the archive, you'll get a
  directory named something like "apache-ant-1.6.0". Rename this
  directory to "ant", and move it to a convenient location. On Windows
  machines, this location is usually "c:\ant". On Unix/linux, this
  location is usually "/usr/local/ant".
  </li>
  <li> Define variables to support ant and Java.
       This will depend on your platform (assuming that your Java version
       is 1.4.2):
  <ul>
  <li> Windows
  <pre>
set ANT_HOME=c:\ant
set PATH=%PATH%;%ANT_HOME%\bin
set JAVA_HOME=c:\j2sdk1.4.2
</pre>
  </li>
  <li> Unix (bash)
  <pre>
export ANT_HOME=/usr/local/ant
export PATH=${PATH}:${ANT_HOME}/bin
export JAVA_HOME=/usr/java/j2sdk1.4.2
</pre>
  </li>
  <li> Unix (csh)
  <pre>
setenv ANT_HOME /usr/local/ant
setenv PATH ${PATH}:/${ANT_HOME}/bin
setenv JAVA_HOME /usr/java/j2sdk1.4.2
</pre>
  </li>
  </ul>
  </li>
  <li> Installation of ant is complete.</li>
  </ul>
  </li>

  <br>
  <li> <b>CVS</b> and <b>SSH</b>, but only if you want to interact directly
  with the cvs tree (which we recommend). The canonical places to get them 
  are <a href="http://www.cvshome.org">www.cvshome.org</a> and
  <a href="http://openssh.org">openssh.org</a>. If you are using Windows,
  your best choice is to install <a
  href="http://cygwin.com">cygwin</a>, which will give you a
  linux-like environment in a command prompt window. Make sure to
  choose "ssh" and "cvs" when you install cygwin.
  </li>
</ul>

  </li>

<br>&nbsp;

  <li>
  <a name="source"><b>Downloading Sphinx-4</b></a>
  <br>&nbsp;
      <ul>
      <li>
      <b>Instructions for retrieving code from a release package.</b>
      <p>
      Sphinx-4 has two packages available for <a href="http://sourceforge.net/project/showfiles.php?group_id=1904&package_id=117949">download</a>:
      <ul>
      <li>
      <b>sphinx4-bin-{version}.zip</b>: 
      provides the jar files, documentation, and demos
      </li>
      <li>
      <b>sphinx4-src-{version}.zip</b>: 
      provides the sources, documentation, demos, unit tests
      and regression tests.
      </li>
      </ul>
      </p>
      <p>
      After you have downloaded these files, unjar the ZIP files using the
      <code>jar</code> command which is in the <code>bin</code> directory of
      your Java installation:
      <pre>
jar xvf sphinx4-bin-{version}.zip
jar xvf sphinx4-src-{version}.zip</pre>
      </p>
      <p>
      If you downloaded sphinx4-bin-{version}.zip, a directory called
      "sphinx4-bin-{version}" will be created. If you downloaded
      sphinx4-src-{version}.zip, a directory called "sphinx4-src-{version}"
      will be created.
      </p>

      <p>
      There are also the RM1 acoustic model, and HUB4 acoustic and language
      models, available for download at the same location on SourceForge.
      Download them only if you want to run the regression tests for RM1 and 
      HUB4.
      </p>

      </li>

      <li><a name="cvs"><b>Instructions for retrieving code from the cvs trees</b></a>
      <p>If you want to be able to get the latest updates from the CVS source
         tree, you should retrieve the code from the CVS source tree on
	 SourceForge. The Sphinx-4 code is located at 
	 <a href="http://sourceforge.net/projects/cmusphinx">sourceforge.net
	 </a> as open source. Please follow the instructions below to retrieve
	 it.</p>
          <ul>
	  <li>Make sure that you set the environment variable CVS_RSH to
	      ssh. See the <a href="#faq">troubleshooting</a> section for more
	      details.
	  </li>

	  <li>Get the code from sourceforge.net. If you are a developer in the
	      cmusphinx project, then do (assuming you use bash shell):
<pre>
% export CVS_RSH=ssh
% cvs -z3 -d:ext:<i>developername</i>@cvs.sourceforge.net:/cvsroot/cmusphinx co sphinx4
</pre>
              where <i>developername</i> is your sourceforge developer name.
	  </li>
	  <li>If you are not a developer, you have to get the code
	  anonymously. When prompted for a password, simply hit
	  &lt;ENTER&gt;:
	    <pre>
% cvs -d:pserver:anonymous@cvs.sourceforge.net:/cvsroot/cmusphinx login
% cvs -z3 -d:pserver:anonymous@cvs.sourceforge.net:/cvsroot/cmusphinx co sphinx4
</pre>
      </li>
    </ul>
    </li>

    </ul>
    </li>
<br>

  <li><a name="how_build"><b>Building Sphinx-4</b></a>
      <p>
      Since the sphinx4-bin-{version}.zip distribution does not contain
      the source code, you must download the sphinx4-src-{version}.zip, or
      retrieved the code from SourceForge using CVS, in order to be able to
      build from the sources. The software required for building Sphinx-4 are 
      listed in the <a href="#download_and_install">Required Software</a> 
      section.
      </p>
      <p>
      To build Sphinx-4, at the command prompt changed to 
      the directory where you installed Sphinx-4 (usually, a simple 
      "cd sphinx4" will do). Set your <code>JAVA_HOME</code> environment
      variable as described above. Then type the following:
      </p>
      <pre>ant</pre>
    <p>
    This executes the <a href="http://ant.apache.org/">Apache Ant</a>
    command to build the Sphinx-4 classes under the <code>bld</code>
    directory, the jar files under the <code>lib</code> directory,
    and the demo jar files under the <code>bin</code> directory.
    </p>
    <p>
    To delete all the output from the build to give you a fresh start:
    <pre>ant clean</pre>
   </li>

  <br>

<li><a name="create_javadocs"><b>Creating Javadocs</b></a>

<p>
The javadocs have already been built if you downloaded the 
sphinx4-bin-{version}.zip. In order to build the javadocs yourself, you must 
download the sphinx4-src-{version}.zip distribution instead. To build the 
javadocs, go to the top level directory ("sphinx4" or 
"sphinx4-src-{version}"), and type:
</p>
<pre>ant javadoc</pre>
<p>This will build javadocs from public classes, displaying only the public methods and fields. In general, this is all the information you will need. If you need more details, such as private or protected classes, you can generate the corresponding javadoc by doing, for example:
</p>
<pre>ant -Daccess=private javadoc</pre>

</li>

<br>&nbsp;

<li><a name="faq"><b>Troubleshooting/FAQ</b></a><br>&nbsp;
<ol>
  <li>How can I specify the location of the Java JDK?
    <ul>

      <li>Using the JAVA_HOME environment variable. For the different
      versions of OS, do:
        <ul>
          <li>
            Unix (t)csh: <code>setenv JAVA_HOME /lab/speech/java/j2sdk1.4.0</code>
          </li>
          <li>
            Unix (ba)sh: <code>export JAVA_HOME='/lab/speech/java/jdk1.4.1_01'</code>
          </li>

          <li>
            Windows/cygwin: <code>export JAVA_HOME='c:/Progra~1/J2SDK_Forte/jdk1.4.0'</code>
          </li>
        </ul>
      </li>
    </ul>
  </li>

  <br>  

  <li>How can I update the code in the current working copy that I have?
    <ul>

      <li>If you are using CVS, you can do a "cvs update -d". The
      switch "-d" will also get new directories or files that have
      been added to the cvs module since the last time you
      downloaded.</li>
    </ul>
  </li>

  <br>

  <li>I always get a "timeout" message when I try to download/update
  the cvs tree.
    <ul>
      <li>Make sure you defined the CVS_RSH environment variable as
      'ssh'. If ssh is not on your path, make sure you specify the
      full path. For the different versions of OS, do:
        <ul>
          <li>
            Unix (t)csh: <code>setenv CVS_RSH ssh</code>

          </li>
          <li>
            Unix (ba)sh: <code>export CVS_RSH='/usr/local/bin/ssh'</code>
          </li>
          <li>
            Windows/cygwin: <code>export CVS_RSH='ssh'</code>
          </li>
        </ul>

      </li>
    </ul>
  </li>

  <br>

  <li><a name="cygwin">What are the limitations/hacks if I am using
  cygwin?</a></li>
  <ul>
    <li>Make sure that you install "ssh" and "cvs" when you install
    cygwin. If you do not want to go through the list of packages
    trying to decide what you need, installing everything is a good
    solution.
    </li>
    <li>Cygwin does not define a home directory, which is used by
    cvs. You have to explicitly define it. You are better off creating
    an environment variable HOME, which will be used by every cygwin
    window that you open. Follow the instructions below to create this
    variable on Windows 2000.
    <ul>

	<li>Assume your userid is "johndoe", and you created a
	directory named "/home/johndoe" in the cygwin environment
        </li>
        <li>Right click on the "My Computer" icon
	</li>
	<li>On the menu, click on "Properties"
	</li>
	<li>Click the "Advanced" tab
	</li>
	<li>Select "Environment Variables"
	</li>
	<li>Click "New" on the "User variables for johndoe" box
	</li>

	<li>On "Variable Name", type "HOME"
	</li>
	<li>On "Variable Value", type "c:\cygwin\home\johndoe"
	</li>
    </ul>
    When you start a new cygwin window, if you type "echo $HOME", you
    should get "/home/johndoe".
    </li>
    <li>Handling absolute paths: Cygwin interprets directory paths in
    a unix-like way, relative to its own "root" directory (which
    cygwin sees as "/" but Windows sees as "c:\cygwin"). However, the
    Java platform interprets directory paths via the operating
    system. Therefore, absolute paths, such as "/lab/speech", will be
    interpreted differently by cygwin and by the Java platform. One
    workaround is to keep the absolute path in Windows (e.g.
    "c:\lab\") and create a link, in cygwin, from that location (such
    as "ln -s /cygdrive/c/lab /lab"). If you use absolute paths to
    identify data location and the directories are not setup this way,
    you may encounter error messages such as:
    </li>
    <pre>
d:\work\sphinx4&gt;ant clean 
/c: Can't open /c: No such file or directory 
</pre>
    <li>Handling DOS 8.3 filename format: Since cygwin deals with unix
    and DOS filename formats at the same time, filenames in different
    files (e.g., build.xml, .props file) have different
    requirements. Paths interpreted directly by cygwin can be as long
    as you want. Paths passed to the program, though, conform to the
    8.3 convention of DOS filenames. Therefore you have to define the
    path to, say, junit as something like
    /lab/speech/ThirdP~1/junit3.7, since this string is passed from
    the environment to the Java code to the OS. </li>
  </ul>
 </ol>
</ul>

<hr>

<h2><a name="demos">Demos</a></h2>

  <p>
  Sphinx-4 contains a number of demo programs. If you downloaded the
  binary distribution (sphinx4-bin-{version}.zip), the JAR files of the demos
  are already built, so you can just run them directly. However, if you
  downloaded the source distribution (sphinx4-src-{version}.zip or via CVS),
  you need to build the demos. Click on the links below for instructions on
  how to build and run the demos.
    <ul>
      <li>
      <a href="demo/sphinx/helloworld/README.html">Hello World Demo</a>: a command line application that recognizes simple phrases
      </li>
      <li>
      <a href="demo/sphinx/hellodigits/README.html">Hello Digits Demo</a>: a command line application that recognizes connected digits
      </li>
      <li>
      <a href="demo/sphinx/hellongram/README.html">Hello N-Gram Demo</a>: a command line application using an N-gram language model for speech recognition
      </li>
      <li>
      <a href="demo/sphinx/zipcity/README.html">ZipCity Demo</a>: a
      Java Web Start technology application that recognizes spoken zip
      codes and locates the associated city and state.
      </li>
    </ul>
  </p>
  <p>
  There is also a <a href="tests/live/README.html">live-mode test program</a>,
  which is available if you download the sphinx-src-{version}.zip file 
  but not available in the sphinx-bin-{version}.zip file.
  </p>
  </li>


<hr>

<h2>Sphinx-4 in Detail</h2>

<ul>

  <li><a name="sphinx_properties"><b>Understanding Sphinx-4
  Configuration Management </b><p>
  
  </a> The document <a
  href="javadoc/edu/cmu/sphinx/util/props/doc-files/ConfigurationManagement.html"> Sphinx-4
  Configuration Management</a> describes, in detail, how to configure a
  Sphinx-4 system.
  

<br>&nbsp;

  <li><a name="sphinx_instrumentation"><b>Understanding Sphinx-4
  Instrumentation </b><p>
  
  </a> The document <a
  href="javadoc/edu/cmu/sphinx/instrumentation/doc-files/Instrumentation.html"> 
  Sphinx-4 Instrumentation </a> describes, in detail, how to use the 
  instrumentation facilities of the Sphinx-4 system.

<br>&nbsp;

<li><a name="batch_tests"><b>Running the Regression Tests</b></a>

  <p>
  Sphinx-4 contains a number of regression tests using common speech databases.
  Again, you have to download the source distribution or downloaded the
  source tree using CVS in order to get the regression tests directory.
  The regression tests we have are:
  </p>
  <ul>
  <li><a href="#isolated_digits_test">Isolated Digits - TI46</a></li>
  <li><a href="#connected_digits_test">Connected Digits - TIDIGITS</a></li>
  <li><a href="#small_vocab_test">Small Vocabulary - AN4</a></li>
  <li><a href="#medium_vocab_test">Medium Vocabulary - RM1</a></li>
  <li><a href="#large_vocab_test">Large Vocabulary - HUB4</a></li>
  </ul>
  <p>
  Before you run any of the tests, make sure that you have built Sphinx-4
  already. To do so, go to the top level and type:
  <pre>ant</pre>
  </p>
  <p>
  You also need to make sure you have the appropriate acoustic model(s)
  installed. More details below.
  </p>
  <p>
  The Sphinx-4 regression tests have different directories for the
  different tasks. The directory sphinx4/tests/performance contains 
  directories named ti46, tidigits, an4, rm1, hub4, and some other tests. 
  Each of these directories contains a build.xml with targets specific 
  to the particular task. The build.xml allows you to run a number of 
  different tests. Type:
  <pre>ant -projecthelp</pre>
  to list a help text with the possible targets.
  </p>

  <p>
  <a name="isolated_digits_test"><br><b>Isolated Digits - TI46</b></a>
  </p>

  <p>
  The TIDIGITS models are already included as part of the distribution.
  Therefore, you do not need to download them separately.
  You must have the TI46 test data, available from the
  <a href="http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC93S9">LDC TI46</a> website.
  </p>
  <p>
  You need to edit the batch file called <code>ti46.batch</code>,
  located in <code>tests/performance/ti46</code> directory.
  You will need to change it such that
  it matches where you stored the TI46 test files. Refer to the section
  <a href="#batch_files">Batch Files</a> for detail about the format of
  batch files.
  </p>
  <p>
  To run the tests:
  </p>
  <pre>
  % cd sphinx4/tests/performance/ti46
  % ant -projecthelp      # to see a list of possible targets
  % ant ti46_wordlist
  </pre>
  
  <p>
  <a name="connected_digits_test"><br><b>Connected Digits - TIDIGITS</b></a>
  </p>

  <p>
  The TIDIGITS models are already included as part of the distribution.
  Therefore, you do not need to download them separately.
  <p>
  You must have the TIDIGITS test data, available from the 
  <a href="http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC93S10">LDC TIDIGITS</a> website.
  <p>
  You need to edit the batch file called <code>tidigits.batch</code>,
  located in the <code>tests/performance/tidigits</code> directory.
  You will need to change it such that
  it matches where you stored the TIDIGITS test files. Refer to the section
  <a href="#batch_files">Batch Files</a> for detail about the format of
  batch files.
  <p>
  To run the tests:

  <pre>
  % cd sphinx4/tests/performance/tidigits
  % ant -projecthelp      # to see a list of possible targets
  % ant tidigits_flat_unigram
</pre>

  <p>
  <a name="small_vocab_test"><br><b>Small Vocabulary - AN4</b></a>

  <p>
  The Wall Street Journal (WSJ) models are already included as part of
  the distribution. Therefore, you do not need to download them separately.
  <p>
  Download the big endian raw audio format of the 
  <a href="http://www.speech.cs.cmu.edu/databases/an4/">AN4 Database</a>.
  Unpack it at a directory of your choice:
  <pre>
  % gunzip an4_raw.bigendian.tar.gz
  % tar -xvf an4_raw.bigendian.tar
</pre>
  <p>
  Then update the following batch files (located in the 
  <code>tests/performance/an4</code>
  directory), so that they match up with where you unpacked the AN4 data.
  You probably just need to replace all instances of the string
  <code>"/lab/speech/sphinx4/data"</code> inside these batch files.
  Please refer to the <a href="#batch_files">Batch Files</a> section for 
  details about batch files:
  <p><code>an4_full.batch<br>an4_spelling.batch<br>an4_words.batch</code>
  <p>
  After you have updated the batch files, you can run the tests by:

  <pre>
  % cd sphinx4/tests/performance/an4
  % ant -projecthelp      # to see a list of possible targets
  % ant an4_words_unigram
</pre>
  
  <p>
  <a name="medium_vocab_test"><br><b>Medium Vocabulary - RM1</b></a>

  <p>
  Make sure that you have downloaded the binary RM1 model file, called
  <code>RM1_13dCep_16k_40mel_130Hz_6800Hz.jar</code>, located at the
  <code>sphinx4</code> package in the <a href="http://sourceforge.net/project/showfiles.php?group_id=1904&package_id=117949">downloads page</a>.
  <br>
  Then in the build file for the RM1 tests,
  <code>sphinx4/tests/performance/rm1/build.xml</code>,
  changed the <code>classpath</code> property of the build file to point to
  the location of your <code>RM1_13dCep_16k_40mel_130Hz_6800Hz.jar</code>.
  <p>
  You must have the RM1 test data, available from the 
  <a href="http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC93S3B">LDC RM1</a> website.

  <p>
  You also need to prepare a batch file called <code>rm1.batch</code>,
  by following instructions in the <a href="#batch_files">Batch Files</a>
  section. There is already one in the RM1 test directory, but it will
  not work for you, since the paths to test files will not match your setup.

  <p>
  To run the tests:

  <pre>
  % cd sphinx4/tests/performance/rm1
  % ant -projecthelp      # to see a list of possible targets
  % ant rm1_bigram
</pre>

  <p>
  <a name="large_vocab_test"><br><b>Large Vocabulary - HUB4</b></a>

  <p>
  You must have the HUB4 test data, available from the 
  <a href="http://wave.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2000S88">LDC HUB4</a> website.
  </p>

  <p>
  You must download the binary HUB4 model file, called 
  <code>HUB4_8gau_13dCep_16k_40mel_133Hz_6855Hz.jar</code>, and the
  binary HUB4 trigram language model, called <code>HUB4_trigram_lm.jar</code>,
  both located at the <code>sphinx4</code> package in the 
  <a href="http://sourceforge.net/project/showfiles.php?group_id=1904&package_id=117949">
  downloads page</a>. For the trigram language model file, unpack it by:
  <pre>jar xvf HUB4_trigram_lm.jar</pre>
  The trigram model file is called <code>language_model.arpaformat.DMP</code>.
  Then, in the build file for the HUB4 tests, 
  <code>sphinx4/tests/performance/hub4/build.xml</code>, 
  changed the <code>classpath</code> property of the build file to 
  point to the location of your 
  <code>HUB4_8gau_13dCep_16k_40mel_133Hz_6855Hz.jar</code>.
  In the configuration file, 
  <code>tests/performance/hub4/hub4.config.xml</code>, change the 'location'
  of the 'trigramModel' component to where your 
  <code>language_model.arpaformat.DMP</code>
  file is located.
  </p>

  <p>
  You also need to prepare a batch file, which is currently called
  <code>f0_hub4.batch</code> in the build.xml file, by following instructions
  in the <a href="#batch_files">Batch Files</a> section.
  </p>

  <p>
  To run the test:

  <pre>
  % cd sphinx4/tests/performance/hub4
  % ant -projecthelp      # to see a list of possible targets
  % ant hub4_trigram
</pre>

  <p>

  </li>

<br>&nbsp;


<li><a name="setup_test"><b>Setting up a Regression Test</b></a>

<p>
Each batch mode regression test consists of the following components:
<ul>
<li><a href="#input_files">Test data</a> - the audio or cepstral data to 
    perform the test on. This is usually some well known database such as 
    TIDIGITS or HUB-4. Alternatively, it can also be data that you recorded on
    your own.
<li><a href="#batch_files">Batch File</a> - this text file lists the location 
    of all the test files, as well as the transcription of the test file.
<li>Acoustic model & Dictionary
<li>Configuration file - specifies the configuration of the system you use to
    test the data.
<li>Grammar file - this can either be a word list file, N-gram language
    model, or a BNF-style grammar file (such as JSGF).
<li><a href="javadoc/edu/cmu/sphinx/tools/batch/BatchModeRecognizer.html">
    Batch-mode Recognizer</a> - this is the Sphinx-4 batch-mode recognizer.
</ul>

<p>To learn about how to setup a regression test, take a look at the
<a href="#an4_walkthrough">walkthrough of setting up the AN4 tests</a>.

<p>
<br><a name="batch_files"><b>Batch Files</b></a>

<p>Batch files are used in batch mode regressions tests. It is a text
file that contains the list of files to be processed, with the
transcription for each file. The format is as shown below: one line
for each file, where the first element in a line is the file name,
which can be an absolute or relative path, and includes the file
extension; after the file name, the words that make up the
transcription for the audio. Sphinx-4 uses the transcription provided
here to compute the system's accuracy after each sentence is
processed. An utterance's processing produces in a hypothesis for what
was said. This hypothesis is compared with the transcription, i.e.,
the hypothesis is aligned against the reference transcript, and a
summary of the results is reported.
</p>

    <pre>
/lab/speech/sphinx4/data/tidigits/test/raw16k/man/man.ah.24z982za.raw two four zero nine eight two zero
/lab/speech/sphinx4/data/tidigits/test/raw16k/man/man.ah.25896o4a.raw two five eight nine six oh four
</pre>

<p>An example batch file is
<a href="tests/performance/tidigits/tidigits.batch">tidigits.batch</a>.

<br>&nbsp;

<p><a name="input_files"><b>Input Audio/Cepstral Files</b></a>

<p>The audio files used by Sphinx-4 can contain raw audio or cepstra,
which is a form of encoded speech. The Java platform has support for
other data formats, such as MS WAV or Sun's au, but, provided as is,
Sphinx-4 can handle only raw data.
</p>
<p>
The audio defaults to 2 bytes/sample, at 16000 samples per second. The
files are expected to be binaries without header. The Java platform
assumes big endian order, always. These defaults can be changed. For
example, the byte order or the sampling rate can be changed.
</p>
<p>
The input can also be cepstra. The cepstral file has a 4 byte integer
containing the number of floats that follow. The following floats are
13 dimensional vectors concatenated. Notice that since the first piece
of information is the number of floats, the total file size can be
computed. If a comparisons with the actual size fails, either the byte
order has to be reversed, or the file is corrupted. Importantly, the
byte order can be automatically detected.
</p>


<p>
<br><a name="an4_walkthrough"><b>Walkthrough of Setting up the AN4 Tests</b></a>
<p>
To illustrate the process of setting up a regression test, lets use AN4,
an existing test, as an example. Use the following steps to create
the AN4 tests.

<p>
<ol>
<li><b>Create a test directory</b> - the various files for each test set 
    (e.g., config file, batch file, grammar files, etc..) should reside
    in its own directory, normally under <code>tests/performance</code>.
    For example, the AN4 tests reside in <code>tests/performance/an4</code>.
<p>
<li><b>Obtain and convert the test database</b> - download the AN4 test 
    database from the <a href="http://www.speech.cs.cmu.edu/databases/an4/">
    AN4 website</a> (choose "Raw audio (.raw) format, big endian byte order").
    Unpack the downloaded tarball into a directory of your choice,
    which in our case is <code>/lab/speech/sphinx4/data/an4</code>.
    Since the AN4 test data
    already comes in raw audio format, no conversion is necessary.
    However, other test databases might require conversion to raw audio.
    For example, the TIDIGITS test files are in SPHERE format, so it is 
    necessary to convert them to raw audio format before it can be read by
    the Sphinx-4 front end. This is usually accomplished by using the
    program <code>sox</code> on UNIX platforms.
<p>
<li><b>Create a batch file</b> - a test database usually contains a 
    transcript (i.e., the actual text of the speech data) of all the 
    test files. Using the transcript file, create a
    <a href="#batch_files">batch file</a>,
    listing the location of the test files and their corresponding transcript.
    For example, our <code>tests/performance/an4/an4_full.batch</code>
    file looks like:
<pre>
/lab/speech/sphinx4/data/an4/an4_clstk/fash/an251-fash-b.raw yes
/lab/speech/sphinx4/data/an4/an4_clstk/fash/an253-fash-b.raw go
/lab/speech/sphinx4/data/an4/an4_clstk/fash/an254-fash-b.raw yes
/lab/speech/sphinx4/data/an4/an4_clstk/fash/an255-fash-b.raw u m n y h six
...
</pre>
    All batch files should reside in the test directory, in this case
    <code>tests/performance/an4</code>.
<p>
<li><b>Acoustic model & Dictionary</b> - use the Wall Street Journal (WSJ) 
    models for the AN4 test, which is already included as a JAR file
    in the binary distribution (sphinx4-bin-{version}.zip). If you downloaded
    the source distribution, building it by running <code>ant</code>
    at the top level directory will create the JAR file for the WSJ model.
    The JAR file should be included in the classpath of the application
    you are deploying. In this case, the WSJ JAR file 
    (<code>lib/WSJ_8gau_13dCep_16k_40mel_130Hz_6800Hz.jar</code>) is included
    in the java command line inside the build.xml run file. We also need
    to specify in the config file (see the next item below) 
    the acoustic model class we are using, which in this case is
    <code>edu.cmu.sphinx.model.acoustic.WSJ_8gau_13dCep_16k_40mel_130Hz_6800Hz
    </code>. The dictionary is also specified in the config file using
    the resource mechanism of Sphinx-4.
<p>
<li><b>Creating the config file & grammar files</b> - 
    In order to create your own configuration file, you must first understand 
    the <a href="javadoc/edu/cmu/sphinx/util/props/doc-files/ConfigurationManagement.html">Sphinx-4 configuration management</a> system.
    The AN4 config file is
    <code>tests/performance/an4/an4.config.xml</code>, please take a look
    at it. This file describes how the batch-mode recognizer and 
    its various sub-components should be configured. Note that this
    file also contains configurations for the live-mode recognizer,
    which is not the subject of interest of this walkthrough.
    In the following we will refer to components in the config file
    using <code>highlights</code>.
    <p>
    In an4.config.xml, the batch-mode recognizer is called <code>batch</code>.
    It uses the Recognizer called <code>wordRecognizer</code>,
    which contains the <code>decoder</code>, as well as
    various monitors that keeps track of recognition accuracy, speed, and
    memory. The <code>decoder</code> contains the <code>searchManager</code>,
    which in turn contains the <code>linguist</code>, the <code>pruner</code>,
    the <code>scorer</code>, and the <code>activeList</code>.
    Refer to the <a href="javadoc/index.html">Javadoc</a> (go to bottom
    of the page) for a description of each of these components.
    The linguist used is the <code>flatLinguist</code>,
    and the grammar of the <code>flatLinguist</code> is either the
    <code>wordListGrammar</code>, which is a file with a list of words, e.g.,
<pre>
AND
APOSTROPHE
APRIL
AREA
AUGUST
CODE
</pre>
    the <code>lmGrammar</code> (i.e., N-gram language model), or 
    <code>fstGrammar</code> (i.e., finite state tranducer grammar).
    The <code>lmGrammar</code> uses a language model file (text-based for AN4)
    generated by the <a href="http://www.speech.cs.cmu.edu/SLM_info.html">CMU
    Statistical Language Modeling (SLM) Toolkit</a>. 

    The <code>flatLinguist</code> also
    specifies the acoustic model used, and in this case it is the WSJ models.
    The location and format of the WSJ model, as well as the location of 
    the various files in the model, are also specified.
    The <code>scorer</code> contains the front end,
    which is called <code>mfcFrontEnd</code> since it produces MFCC features.
<p>
<li><b>Creating a build.xml for Ant</b> - a file called <code>build.xml</code>
    is necessary to run Ant. This file is the Ant version of the Makefile
    in Make. All Ant targets are listed in this file.
    For details on how to write this file, refer to the documentation
    at <a href="http://ant.apache.org/">http://ant.apache.org/</a>.
    Lets use the first Ant target, <code>an4_words_wordlist</code>, as an
    example. This Ant target invokes the <code>java</code> command
    on the class <code>edu.cmu.sphinx.tools.batch.BatchModeRecognizer</code>.
    This class takes a configuration file (<code>an4.config.xml</code>)
    and a batch file (<code>an4_words.batch</code>) as arguments.
    This class looks for the component named <code>batch</code>
    in the configuration file. The configuration manager will create this
    component (and its subcomponents). Therefore, the component 
    <code>edu.cmu.sphinx.tools.batch.BatchModeRecognizer</code> should always
    be named <code>"batch"</code> in the config.xml file.

    Other AN4 Ant targets are created similarly.
<p>
<li><b>Setup Complete</b> - At this point, we have completed the setup
    of the AN4 tests. You can now run the AN4 tests by following instructions
    in <a href="#small_vocab_test">small vocabulary tests</a>.

</ol>

</li>

<br>&nbsp;


<li><a name="acoustic_models"><b>Acoustic Models</b></a>

<p>
The two main acoustic models that are used by Sphinx-4, TIDIGITS and
Wall Street Journal, are already included in the <code>"lib"</code>
directory of the binary distribution. For the source distribution, you will
build it when you type <code>ant</code> at the top level directory. 
Our regression tests also uses the RM1 and HUB4 models,
which are available for download separately on the download page.
Sphinx-4 can handle model packages provided as a jar file. 
</p>
<p>
Each acoustic model implements the 
<a href="javadoc/edu/cmu/sphinx/linguist/acoustic/AcousticModel.html">
AcousticModel interface</a>. For example, the WSJ models are wrapped by
a class called <code>edu.cmu.sphinx.model.acoustic.WSJ_8gau_13dCep_16k_40mel_130Hz_6800Hz</code>, which implements the AcousticModel interface.
This implementation class is in the JAR file of the models, together
with the actual data files of the model. This way, two simple steps are
need to use a particular acoustic model:
</p>
<ol>
<li>Include the JAR file in your classpath.</li>
<li>Specify the model implementation class in the config file.</li>
</ol>
<p>
You can find out the model implementation class of a JAR file using the
<code>java -jar</code> command. For example, you can find out the model
class of the WSJ model by:
<pre>
sphinx4>java -jar lib/WSJ_8gau_13dCep_16k_40mel_130Hz_6800Hz.jar

Wall Street Journal acoustic models
Class: edu.cmu.sphinx.model.acoustic.WSJ_8gau_13dCep_16k_40mel_130Hz_6800Hz
        Is Binary: true
        Sparse Form: false
        Filters: 40
        Vector Length: 39
	Gaussians: 8
	Model Definition: etc/WSJ_clean_13dCep_16k_40mel_130Hz_6800Hz.4000.mdef
	Data Location: cd_continuous_8gau
	Feature Type: cepstra_delta_doubledelta
	Sample Rate: 16000
	Description: Wall Street Journal acoustic models
	Number Fft Points: 512
	Max Freq: 6800
	Min Freq.: 130
</pre>
The print out also includes details about how the model was trained, but
this is not important for the average user.
</p>

</li>

<br>&nbsp;

<li><a name="language_models"><b>Language Models</b></a>

<p>The language model used by Sphinx-4 follows the ARPA
format. Language models provided with the acoustic model packages were
created with the Carnegie Mellon University Statistical Language
Modeling toolkit (CMU SLM toolkit), available <a
href="http://www.speech.cs.cmu.edu/SLM_info.html">at CMU</a>. A manual
is available there.</p>

<p>The language model is created from a list of transcriptions. Given
a file with training transcription, the following script
creates a list of words that appear in the transcriptions, then
creates a bigram and a trigram LM files in the ARPA format. The file with extension ccs contains the context cues, and it is usually a list of words used as markers - beginning or end of speech etc.</p>

<pre>
set task = RM

# Location of the CMU SLM toolkit
set bindir = ~/src/CMU-SLM_Toolkit_v2/bin

cat $task.transcript | $bindir/text2wfreq | $bindir/wfreq2vocab > $task.vocab

set mode = "-absolute"

# Create bigram
cat $task.transcript | $bindir/text2idngram -n 2 -vocab $task.vocab | \
   $bindir/idngram2lm $mode -context $task.ccs -n 2 -vocab $task.vocab \
   -idngram - -arpa $task.bigram.arpa

# Create trigram
cat $task.transcript | $bindir/text2idngram -n 3 -vocab $task.vocab | \
   $bindir/idngram2lm $mode -context $task.ccs -n 3 -vocab $task.vocab \
   -idngram - -arpa $task.trigram.arpa
</pre>

</li>


<br>&nbsp;

<li><a name="bnf_grammars"><b>BNF-Style Grammars</b></a>

<p>
Sphinx-4 uses the Java Speech API Grammar Format (JSGF) to perform 
speech recognition using a BNF-style grammar. Currently, you can only
use JSGF grammars with the FlatLinguist. To specify JSGF grammars, 
set the following in the configuration file:

<pre>
&lt;component name="flatLinguist" type="edu.cmu.sphinx.linguist.flat.FlatLinguist"&gt;
    &lt;property name="grammar" value="jsgfGrammar"&gt;
    // ... other properties ...
&lt/component&gt;

&lt;component name="jsgfGrammar" type="edu.cmu.sphinx.jsapi.JSGFGrammar"&gt;
    &lt;property name="grammarLocation" value="...URL of grammar directory"/&gt;
&lt/component&gt;
</pre>

<p>
For information on how to write JSGF grammars, and how to
specify the location of your JSGF grammar file(s), and the limitations of 
the current implementation of JSGF grammar, please refer to the 
<a href="javadoc/edu/cmu/sphinx/jsapi/JSGFGrammar.html">Javadocs for
JSGFGrammar</a>.

</li>


<br>&nbsp;

  <li>
     <a name="architecture_and_api1"><b>Architecture and API</b></a>
     <p>
     The Sphinx-4 API can be found in the 
     <a href="javadoc/index.html">javadoc documentation</a>.
     </p>
     <p>
     If the previous is broken, please build the javadocs using the
     instructions in <a href="#create_javadocs">Creating Javadocs</a>.
     In fact, rebuilding javadocs is something you should do every time
     you change code in Sphinx-4.
     </p>

     <p>
     In this section, we will provide an overview of Sphinx-4, starting with 
     an introduction of HMM-based recognizers. We will highlight in 
     <s4keyword>red</s4keyword> those keywords that are critical to 
     understanding Sphinx-4.
     </p>

     <h4>Overview of an HMM-based Speech Recognition System</h4>

  <p>
  Sphinx-4 is an HMM-based speech recognizer. <s4keyword>HMM</s4keyword>
  stands for Hidden Markov Models, which is a type of statistical model.
  In HMM-based speech recognizers,
  each unit of sound (usually called a phoneme) is represented by a statistical
  model that represents the distribution of all the evidence (data) for
  that phoneme. This is called the <s4keyword>acoustic model</s4keyword> 
  for that phoneme. When creating an acoustic model,
  the speech signals are first transformed into a sequence of vectors
  that represent certain characteristics of the signal, and the
  parameters of the acoustic model are then estimated using these vectors
  (usually called <s4keyword>features</s4keyword>). This process is called 
  training the acoustic models.
  </p>

  <p>
  During speech recognition, features are derived from the 
  incoming speech (we will use "speech" to mean the same thing as "audio")
  in the same way as in the training process. The component of the recognizer
  that generates these features is called the <s4keyword>front end</s4keyword>.
  These live features are scored against the acoustic model.
  The <s4keyword>score</s4keyword> obtained indicates how 
  likely that a particular set of features (extracted from live
  audio) belongs to the phoneme of the corresponding acoustic model.
  </p>

  <p>
  The process of speech recognition is to find the best possible sequence
  of words (or units) that will fit the given input speech. It is a 
  <s4keyword>search</s4keyword> problem, and in the case of HMM-based 
  recognizers, a graph search problem. The graph represents all possible
  sequences of phonemes in the entire <s4keyword>language</s4keyword>
  of the task under consideration. The graph is typically
  composed of the HMMs of sound units concatenated in a guided manner,
  as specified by the <s4keyword>grammar</s4keyword> of the task. 
  As an example, lets look at a simple search graph that decodes the words
  "one" and "two". It is composed of the HMMs of the sounds units of the
  words "one" and "two":
  </p>

  <img src="doc/1-2-searchgraph.jpg">

  <p>
  Constructing the above graph requires knowledge from various sources.
  It requires a <s4keyword>dictionary</s4keyword>, which maps the word
  "one" to the phonemes W, AX and N, and the word "two" to T and OO.
  It requires the acoustic model to obtain the HMMs for the phonemes
  W, AX, N, T and OO. In Sphinx-4, the task of constructing this search graph
  is done by the <s4keyword>linguist</s4keyword>.
  </p>

  <p>
  Usually, the search graph also has information about how likely certain
  words will occur. This information is supplied by the
  <s4keyword>language model</s4keyword>. Suppose that, in our example,
  the probability of someone saying "one" (e.g., 0.8) is much higher than 
  saying "two" (0.2). Then, in the above graph, the probability of the
  transition between the entry node and the first node of the HMM for W
  will be 0.8, while the probability of the transition between the entry
  node and the first node of the HMM for T will be 0.2. The path to
  "one" will consequently have a higher score.
  </p>

  <p>
  Once this graph is constructed, the sequence of parametrized speech
  signals (i.e., the features) is matched against different paths 
  through the graph to find the best fit. 
  The best fit is usually the least cost or highest
  scoring path, depending on the implementation.
  In Sphinx-4, the task of searching through the graph for the best path
  is done by the <s4keyword>search manager</s4keyword>.
  </p>

  <p>
  As you can see from the above graph, a lot of the nodes have self
  transitions. This can lead to a very large number of possible paths
  through the graph. As a result, finding the best possible path can
  take a very long time. The purpose of the <s4keyword>pruner</s4keyword>
  is to reduce the number of possible paths during the search,
  using heuristics like pruning away the lowest scoring paths.
  </p>

  <p>
  As we described earlier, the input speech signal is transformed into a
  sequence of feature vectors. After the last feature vector is decoded,
  we look at all the paths that have reached the final exit node 
  (the red node). The path with the highest score is the best fit, and a 
  <s4keyword>result</s4keyword> taking all the words of that path is returned.
  </p>

  <h4><a name="architectureComponents">Sphinx-4 Architecture and Main Components</a></h4>

  <p>
  In this section, we describe the main components of Sphinx-4, and how
  they work together during the recognition process. First of all,
  lets look at the architecture diagram of Sphinx-4. It contains almost
  all the concepts (the words in red) that were introduced in the previous
  section. There are a few additional concepts in the diagram, 
  which we will explain promptly.
  </p>

  <center>
  <img src="doc-files/architecture.gif">
  </center>

  <p>
  When the recognizer starts up, it constructs the front end (which generates
  features from speech), the decoder, and the linguist (which generates 
  the search graph) according to the configuration specified by the user.
  These components will in turn construct their own subcomponents. For example,
  the linguist will construct the acoustic model, the dictionary,
  and the language model. It will use the knowledge from these three
  components to construct a search graph that is appropriate for the task. 
  The decoder will construct the search manager,
  which in turn constructs the scorer, the pruner, and the active list.
  </p>

  <p>
  Most of these components represents interfaces. The search manager,
  linguist, acoustic model, dictionary, language model, active list, scorer,
  pruner, and search graph are all Java interfaces. There can
  be different implementations of these interfaces. For example,
  there are two different implementations of the search manager.
  Then, how does the system know which implementation to use? It is specified
  by the user via the configuration file, an XML-based file that is loaded 
  by the <s4keyword>configuration manager</s4keyword>. In this configuration
  file, the user can also specify the <s4keyword>properties</s4keyword>
  of the implementations. One example of a property is the sample rate 
  of the incoming speech data.
  </p>

  <p>
  The <s4keyword>active list</s4keyword> is a component that requires 
  explanation. Remember we mentioned that there can be many possible paths
  through the search graph. Sphinx-4 currently implements a 
  <s4keyword>token</s4keyword>-passing algorithm. Each time the search arrives
  at the next state in the graph, a token is created. A token points to the 
  previous token, as well as the next state. The active list keeps track of 
  all the current active paths through the search graph by storing the last
  token of each path. A token has the score of the path at that particular
  point in the search. To perform pruning, we simply prune the tokens in the
  active list.
  </p>  

  <p>
  When the application asks the recognizer to perform recognition,
  the search manager will ask the scorer to score each token in the
  active list against the next feature vector obtained from the front end.
  This gives a new score for each of the active paths. The pruner will then 
  prune the tokens (i.e., active paths) using certain heuristics. 
  Each surviving paths will 
  then be expanded to the next states, where a new token will be created 
  for each next state. The process repeats itself until no more feature 
  vectors can be obtained from the front end for scoring. This usually 
  means that there
  is no more input speech data. At that point, we look at all paths 
  that have reached the final exit state,
  and return the highest scoring path as the result to the application.
  </p>

  <h4><a name="configuration">Sphinx-4 Configuration System</a></h4>

  <p>
  The performance of Sphinx-4 critically depends on your task and how
  you configured Sphinx-4 to suit your task. For example, 
  a large vocabulary task needs a different linguist than a small 
  vocabulary task. Your system has to be configured differently
  for the two tasks. This section will not tell you the exact configuration
  for different tasks, which will be dealt with later. Instead, this section
  will introduce you to the configuration mechanism of Sphinx-4, which is
  via an XML-based configuration file. Please click on the document
  <a href="javadoc/edu/cmu/sphinx/util/props/doc-files/ConfigurationManagement.html">Sphinx-4 Configuration Management</a> to learn how to do this.
  It is important that you read this document before you proceed.
  </p>

  </li>
  <br>&nbsp;


</ul>



<hr>

Copyright 1999-2004 Carnegie Mellon University.<br>
Portions Copyright 2002-2004 Sun Microsystems, Inc.<br>
Portions Copyright 2002-2004 Mitsubishi Electric Research Laboratories.<br>
All Rights Reserved.  Usage is subject to 
<a href="license.terms">license terms</a>.

</font>
</body>
</html>
