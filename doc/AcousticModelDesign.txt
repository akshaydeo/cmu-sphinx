Sphinx3j Acoustic Model

This document describes the requirements, interfaces and high level
design for the Acoustic Model of Sphinx3j. There are some questions
embedded in this document. They are marked as follows:

  - [[[QFSE - this marks a "Question For Speech Expert"]]]
  - [[[QFJE - this marks a "Question For Java Expert"]]]
  - [[[QFSA - this marks a "Question For the Sphinx3j Architect"]]]

Acoustic Model Requirements  Version 0.2
----------------------------------------
-  The Acoustic Model provides a set of objects and interfaces that
   can be used by entities for acoustic scoring of features.

-  Mutation - Acoustic Models may be adapted during the course
   of recognition. The Acoustic Model should provide a mechanism for
   identifying subsets of the A.M. that are immutable and potentially
   allow these to be shared among different acoustic models. The

-  Persistence of Adaptation - An acoustic model may be adapted over the
   course of time. This adaptation should optionally be persistent 
   across runs. 

-  The acoustic model will be used by the trainer, and thus needs to
   support (eventual) trainer type operations (including saving). The
   training interfaces will NOT be included in the initial design and
   implementation.

-  The Acoustic Model will provide interfaces for adapting the model.
   The detailed adaptation requirements have not determined as of this
   time.  [[[ QFSE - what are the Adaptation requirements? ]]]
    
-  The Acoustic model can be read in from a file or a set of files.

-  There could potentially be more than one Acoustic Model in the
   system at a time.

-  The acoustic model consists of a pool of Hidden Markov Models
   (HMMs).

-  Each HMM is associated with a single unit of speech. A unit can 
   be a phone, a word, or any other segment of speech.

-  The HMMs are left-right HMMs.

-  There can be an arbitrary number of states per HMM.  

-  The number of states per HMM can vary from one HMM to the next.

-  An HMM contains at least the following information:

   	- A description of the unit of speech that the HMM models.

	- The context for the unit of speech.  The context consists
	  of:

	     - The set of units (of arbitrary size) preceeding this
	       unit.

	     - The set of units (of arbitrary size) following this
	       unit.

  	- A transition matrix that details the probability of a state
	  transition between each state of the HMM.  The transition
	  matrix is a 2 dimensional matrix of size N by N where N is
	  the number of states. [[ QUESTION - with the
	  one-step-viterbi design, do we sill need the non-emitting
	  entry and exit states? If so then the matrix should be
	  dimensioned N+1 by N+1 to include the probability of
	  transitioning toe the non-emitting exit state.]]

	- A set of senone sequences, or composite senone sequeneces


-   A Senone sequence is an ordered list of senones. Each senone in a 
    senone sequence corresponds to an HMM state. Thus a 5 state HMM 
    will point to a senone sequence that contains 5 senones.

-   A composite senone sequence is a list of sets of senones. Each
    element in a composite senones sequence list is the set of
    possible senones for that state.  Composite senone sequences are 
    used by HMMs to represent units where the left and/or right 
    contexts are unknown.  
    
    [[[QFSE: Can composite senone sequences be
    replaced by SenoneSequences that represent simple and composite
    senones?]]

-   Senone sequences are maintained in a pool so they can be shared 
    among different HMMs

-   Composite senone sequences are maintained in a pool so they can 
    be shared among different HMMs. 
    
-   The sharing of senones and composite senones not only reduces 
    memory footprint but also can reduce  processing time since 
    shared senones need only be scored once per frame.

-   A fundamental property of a senone is that it can be scored
    against a Feature.

-  The Acoustic Scorer (the part of the system responsible for scoring
   all senones for a particular frame) may call on the acoustic model
   to score individual senones, but is not part of the acoustic model.

   [[[ QFSA: Should subvector quantization management be
   considered part of the Acoustic Model? It seem to me that this is
   part of the Acoustic Score (meaning that I think the answer is no)
   ]]]

-   A senone is essentially a probability distribution function (PDF).
    It can be represented by an abstract interface.  

-   One implementation of the senone interface is to represent the PDF as
    a Mixture Gaussian. The Mixture Gaussian will be the first
    implementation of the senone interface.

-   The Mixture Gaussian consists of:

    	- A set of MixtureWeights, one weighting for each component.

	- A set of Mixture components each of which contains:

	    - Mean vector

	    - MeanTransformationMatrix

	    - Variance Vector

	    - VarianceTransformationMatrix

-   Each of the members that form the MixtureComponent shall be
    kept in a pool so that the elements can be shared by
    different mixture components.

-   The format of the Mixture Gaussian input file shall be defined by
    the output of the Sphinx3 trainer.

-  Database sizes:

	Note that it is somewhat difficult to predict the senone size
	since many of the components may be shared. This is a rough
	(order of magnitude) estimate of the size of the Senones and
	HMMs for the various reference applications.

	[[[ QFSE: I don't have real high confidence in these numbers.
	Could you take a look and verify that these are within an
	order of magnitude? ]]]



	senone size:
		8-16 Mixtures
		    39 Means
		    39 Variance
		    39x39 Xform Matrix (shared)
		    39x39 Xform Matrix (shared)
	Estimate a typical senone
		is 8 * 39 * 2 * 4 + shared = 4K

	HMM Size: (for a 3 state)
		4x4 matrix
		Name
		Senone/Composite senone sequence  
	Typical HMM: about 100 bytes

	Large Vocabulary:
		100,000 HMMS = 10MB
		8000 Senones = 32MB

	Command and Control
		300 HMMs 	= 30K
		400 Senones	= 1.6MB

	Connected Digits
		300 HMMs 	= 30K
		400 Senones	= 1.6MB


Acoustic Model High Level Interfaces
----------------------------------------
This section describes the high level interfaces provided by the
Acoustic Model.  These are a set of generic classes and interfaces 
that provide the overall interface to the AcousticModel. 

/**
 * Represents the generic interface to the Acoustic 
 * Model for sphinx3j
 */
public class AcousticModel {

     /**
      * Initializes an acoustic model of a given context. This method
      * should be called once per context. It is used to associate a
      * particular context with an acoustic model resource. 
      *
      * @param context	the context of interest
      * @param url	the location of the acoustic model data for
      * 		context
      *
      * @throws IOException if the model could not be loaded
      * @throws FileNotFoundException if the model does not exist
      */
     public static void initAcousticModel(String context, URL url);

     /**
      * Gets the acoustic model for the given context. This is a
      * factory method that gets the acoustic model for this given
      * context. 
      *
      * @param context the context of interest
      *
      * @return the acoustic model associated with the context or null
      * if the given context has no associated acoustic model
      */
     public static AcousticModel getAcousticModel(String context);

  // [[[ NOTE: I am currently not too sure what the language
  // model or search/Decode systems are going to need beyond
  // looking up an HMM for a particular unit, I would guess that as
  // the decoder and LM designs solidify that a few more interfaces
  // may be added ]]

     /**
      * Given a unit, return the HMM that exactly matches the given
      * unit.  
      *
      * @param unit 	the unit of interest
      *
      * @return 	the HMM that exactly matches, or null if no match
      * 		could be found.
      */
     public HMM lookup(Unit unit);

     /**
      * Returns an iterator that can be used to iterate through all
      * the HMMs of the acoustic model
      *
      * @return an iterator that can be used to iterate through all
      * HMMs in the model
      */
      // [[[ NOTE: I'm not sure that we even need this ]]]
     Iterator iterator();
}

/**
 * Represents a unit of speech. Units may represent phones, words or
 * any other suitable unit
 */
interface Unit {

    /**
     * Gets the name for this unit
     *
     * @return the name for this unit
     */
    public String getName();
}

/**
 * Represents a context dependent unit of speech.  The context of a
 * unit is defined as the set of units to the left (preceding) and to
 * the right (following) this unit. [[[ QUESTION: Should we allow for
 * other types of context dependent units,(part of speech for example?) ]]]
 */
interface ContextDependentUnit extends Unit {
    /**
     * Gets the left context for the unit
     * 
     * @return the left context for a unit, or null if the unit has
     * no left context
     */
    public Unit[] getLeftContext();

    /**
     * Gets the right context for the unit
     * 
     * @return the right context for a unit, or null if the unit has
     * no right context
     */
    public Unit[] getRightContext();
}


/**
 * Represents a hidden-markov-model. An HMM consists of a unit
 * (context dependent or independent), a transition matrix from state
 * to state, and a sequence of senones associated with each state.
 */
interface HMM {
    /**
     * Gets the  unit associated with this HMM
     *
     * @return the unit associated with this HMM
     */
    public Unit getUnit();


    /**
     * Returns the order of the HMM
     *
     * @return the order of the HMM
     */
    // [[[NOTE: this method is probably not explicitly needed since
    // getSenoneSequence.getSenones().length will provide the same
    // value, but this is certainly more convenient and easier to
    // understand
    public int getOrder();


    /**
     * Returns the SenoneSequence associated with this HMM
     *
     * @return the sequence of senones associated with this HMM. The
     * length of the sequence is N, where N is the order of the HMM
     */
    // [[ NOTE: the senone sequence may in fact be a sequence of
    // composite senones
    public SenoneSequence getSenoneSequence();


    /**
     * Returns the transition matrix that determines the state
     * transition probabilities for the matrix
     *
     * @return the transition matrix of size NxN where N is the order
     * of the HMM
     */
    public float[][] getTransitionMatrix();

    // [[ NOTE: For convenience we could provide some methods that
    // return slices of the matrix (depending on the reqs. of the
    // decoder

}

/**
 * Contains an ordered list of senones. 
 */
interface SenoneSequence {
    /**
     * Returns the ordered set of senones for this sequence
     *
     * @return	 the ordered set of senones for this sequence
     */
    public Senone[] getSenones();
}

/**
 * Represents a set of acoustic data that can be scored against a
 * feature
 */
interface Senone {
    /**
     * Calculates the score for this senone based upon the given
     * feature.
     *
     * @param feature	the feature vector to score this senone
     * 			against
     *
     * @return 		the score for this senone
     */
    public float getScore(Feature feature);
}

Acoustic Model Low Level Interfaces
----------------------------------------
This is the next level down of the AcousticModel interfaces. It shows
some of the concrete implementations of the abstract interfaces
described  in the 'high-level' interfaces document. These classes are
to be defined as 'package private' and will not be visible outside of
the Acoustic Model package.

Note that these structures are built from components that may be
shared with other objects of the same type. For instance, Several
mixture components may share the same meanTransformationMatrix.  These
shared components are maintained in pools.  It is up to the acoustic
model loader to create and manage these component pools and manage the
sharing of these objects.  The acoustic model loader and the pool
manager will be described in a subsequent step.


[[[ QFSE - Is there enough precision in a Java float (32 bits) to
    represent the GaussianMixture data and the resulting score? Note
    that java floats are essentially 32-bit IEEE 754 values, and java
    doubles are 64-bit IEEE 754 values.

    Float
    	bits of precision:		24
	Exponent bits:			8
	Decimal digits of precision:	7.22
	Maximum Magnitude:		3.4028E+38
	Minimum Magnitude:		1.1754E-38

    Double
    	bits of precision:		53
	Exponent bits:			11
	Decimal digits of precision:	15.95
	Maximum Magnitude:		1.7976E+308
	Minimum Magnitude:		2.2250E-308
]]]


[[[ QFSE QFJE - Many of my questions have to do with Acoustic Model
adaptation. We have not talked yet to any depth about adaptation, so I
do not have a good feel for how it would work or how to provide an
interface for it. Perhaps we can just chose to acknowledge that we
will do some adaptation of models in the future, but for the short
term not worry too much about constructing interfaces to it. Any
thoughts?
]]]

/**
 * 
 * Represents a concrete implementation of a simple senone. A simple
 * senone is a set of probability density functions implemented  as a
 * gaussian mixture.
 */
class GaussianMixture implements Senone {
    // these data element in a senone may be shared with other senones
    // and therefore should not be written to.
    private float[] mixtureWeights;			
    private MixtureComponent[] mixtureComponents;	

    /**
     * Creates a new senone from the given components.
     *
     * @param mixtureWeights the mixture weights for this senone
     * @param  mixtureComponents the mixture comopnents for this
     * senone
     */
    public GaussianMixture(float[] mixtureWeights, 
    		MixtureComponent[] mixtureComponents);

    
    /**
     * Calculates a score for the given feature based upon this senone
     *
     * @param feature the feature to score
     *
     * @return the score for the feature
     */
    public float getScore(Feature feature); 

    /* [[[ QFSE - I assume that mixtureWeights are used for adaptation.
    Is this correct? What would be an approriate interface for
    modifying mixture weights? Perhaps something as simple as this:

    public float getMixtureWeights();
    public void setMixtuerWeights(float[] mixtureWeights);

    ]]] */
}


/**
 * Represents a composite senone. A composite senone consists of a set
 * of all possible senones for a given state
 */
 [[[ QFSE - Note that there is no CompositeSenoneSequence class.
 Instead there is just a SenoneSequence class that represents
 sequences of senones (simple or composite). This would allow us to
 easily represent sequences that are mixtures of simple and composite
 sequences.  The question is: Is there any reason to maintain
 CompositeSeneoneSequences explicitly and separately from
 SimpleSenone sequences?
 ]]]

class CompositeSenone implements Senone {
    private Senone[] senones;


    /**
     * Constructs a CompositeSenone given the set of constiuent
     * senones
     *
     * @param senones the set of constiuent senones
     *
     */
    public CompositeSenone(Senone[] senones);

    /**
     * Calculates the composite senone score. Typically this is the
     * best score for all of the constituent senones
     *
     * @param feature the feature to score
     *
     * @return the score for the feature
     */
    public float getScore(Feature feature);
}


/**
 * defines the set of shared elements for a GaussianMixture. Since
 * these elements are potentially shared by a number of
 * GaussianMixtures, these elements should not be written to. The
 * GaussianMixture defines a single probability density function along
 * with a set of adaptation parameters 
 *
 */
 // [[[ QFSE: I'm still a bit unsure
 //  of the role of the Transformation Matrices and Vectors, are 
 // these use for adaptation?  ]]]

 // [[[ QFSE: Since many of the subcomponents of a
 // MixtureComponent are shared, are there some potential
 // opportunities to reduce the number of computations in scoring
 // senones by sharing intermediate results for these subcomponents?
 //  ]]]

class MixtureComponent {
    private float[]   mean;
    private float[][] meanTransformationMatrix;
    private float[]   meanTransformationVector;
    private float[]   variance;
    private float[][] varianceTransformationMatrix

    /**
     * Create a MixtureComponent with the given sub components
     *
     * @param mean	the mean vector for this PDF
     * @param meanTransformationMatrix TBD NOT SURE
     * @param meanTransformationVector TBD NOT SURE
     * @param variance  the variance for this PDF
     * @param varianceTransformationMatrix  TBD NOT SURE
     */
    MixtureComponent(
	private float[]   mean;
	private float[][] meanTransformationMatrix;
	private float[]   meanTransformationVector;
	private float[]   variance;
	private float[][] varianceTransformationMatrix); 

    // [[[ QFSE QFJE
    // I'm not sure of the best interface for this class, that depends
    // on how the GaussianMixture.getScore method wants to be written.
    // Some options are (given in order of preference):
    //
    // push the scoring down to this level:
    //
    //		float getScore(Feature feature)
    //
    //  provide accessor methods to all elements, like so:
    //
    //		float[] getMean()
    //		float[] getMeanTransformationMatrix()
    //		float[] getMeanTransformationVector()
    //		float[] getVariance()
    //		float[] getVarianceTransformationMatrix()
    //
    //
    // Or provide direct access to the elements, (that is, remove the
    // 'private' qualifier from the data declarations in this class.)
    // ]]]

    /**
     * Score this mixture against the given feature
     *
     * @param feature the feature to score
     *
     * @return the score for the given feature
     */
     float getScore(Feature feature);

     // [[[ QFSE: Once again, I am not sure what the proper adaptation
     // interface should look like. We really have not talked enough
     // about adaptation at this point for us to decide on an
     // interface for it. I'll just leave it out for now.
}
