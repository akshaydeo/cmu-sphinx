<!DOCTYPE html PUBLIC "-//IETF//DTD HTML 2.0//EN">

<!--

Copyright 1999-2004 Carnegie Mellon University.
Portions Copyright 2004 Sun Microsystems, Inc.
Portions Copyright 2004 Mitsubishi Electric Research Laboratories.
All Rights Reserved.  Use is subject to license terms.

See the file "license.terms" for information on usage and
redistribution of this file, and for a DISCLAIMER OF ALL
WARRANTIES.

-->



<html>

<head>
  <title>Sphinx-4 Frequently Asked Questions</title>
   <style TYPE="text/css">
     pre { padding: 2mm; border-style: ridge; background: #f0f8ff; color: teal;}
     code {font-size: medium; color: teal}
   </style>
</head>

<body>
  <font face="Arial">
  <table bgcolor="#99CCFF" width="100%">
    <tr>
      <td align=center width="100%">
        <center><font face="Times New Roman"><h1>Sphinx-4 Frequently
        Asked Questions</h1></font></center>
      </td>
    </tr>
  </table>
  </font>

<ul>
    <li> <b>Who created Sphinx-4?</b> </li>

    <blockquote>
    Sphinx-4 was created via a joint collaboration between the Sphinx group
    at Carnegie Mellon University, Sun Microsystems Laboratories,
    Mitsubishi Electric Research Labs (MERL), and Hewlett Packard
    (HP), with contributions from the University of California at
    Santa Cruz (UCSC) and the Massachusetts Institute of Technology
    (MIT).
    </blockquote>

    <li> <b>I have a question about Sphinx-4. How can I get it
    answered?</b></li>
    <blockquote>
        First, check this FAQ, 
        many questions are answered here. If your question is not in
        the FAQ, you can post it to the <a
        href="http://sourceforge.net/forum/forum.php?forum_id=382337">
        Sphinx4 Open Discussion Forum</a> on SourceForge. Many of the
        Sphinx-4 developers monitor this forum and answer technical
        questions.
    </blockquote>

    <li> <b>How can I contact the Sphinx-4 team?</b> </li>

    <blockquote>
    You can contact the Sphinx-4 team by sending email to 
    <i>cmusphinx-contacts at sourceforge dot net. </i>
    </blockquote>

    <li> <b>How well does Sphinx-4 perform compared to other speech
    recognizers?</b> </li>

    <blockquote>
    Comparing speech recognizers is often difficult. Speed and
    accuracy data for commercial recognizers is not typically
    available.  We have compared Sphinx-4 with the Sphinx 3.3
    recognizer. Results of this comparison are here: <a
    href="../index.html#speed_and_accuracy">Sphinx-4 Performance Comparison</a>
    </blockquote>

    <li> <b> Isn't the Java Platform too slow to be used for speech
    recognition?</b></li>

    <blockquote>
      No, rumors of the poor performance of the Java platform are
      unfounded. Sphinx-4 runs faster than Sphinx 3.3 (CMUs
      <i>fast</i> recognizer) for many tests.  
      For a good discussion of Java platform
      performance in speech engines look at <a
      href="http://www.sunlabs.com/techrep/2002/abstract-114.html">FreeTTS
      - A Performance Case Study</a> a technical paper that compares
        the performance of speech synthesis engine written in the Java
        programming language to its native-C counterpart.
    </blockquote>

    <li> <a name="which_dist"><b>Which Sphinx-4 distribution should I
    use?</b></a></li>
    <blockquote>

    Download the binary distribution if:
    <ul>

    <li> You just want to check out Sphinx-4 by running the demos.
    <li> You want to build applications using Sphinx-4, but you don't
      want to touch the source code of Sphinx-4.
    </ul>

      Download the source distribution if you want to do everything
      above, plus:
      <ul>
        <li> You want to get all the source code of Sphinx-4, so that you
        can understand how Sphinx-4 works, and do your experimentation
        with Sphinx-4.
        <li> You want to build Sphinx-4 from the ground up.
        <li> You want to run the unit tests.
        <li> You want to run the regression tests.
      </ul>

    </blockquote>

    <li> <b>Does Sphinx-4 support the Java Speech API (JSAPI)?</b></li>
    <blockquote>
       Currently, Sphinx-4 does not support the full Java Speech API.
       Instead, Sphinx-4 uses lower-level <a
       href="../javadoc/index.html">API</a>.
       However, Sphinx-4 does support <a
       hfref="http://java.sun.com/products/java-media/speech/forDevelopers/JSGF/">Java
       Speech Grammar Format</a> (JSGF)
       grammars.
    </blockquote>

    <li> <b>I want to add speech recognition to my application. Where
    do I start?</b></li>

    <blockquote>
    First, look at the sourcecode for <a href="../index.html#demos">Sphinx-4
    demos</a> to get a feel for how to write a Sphinx-4 application.
    After that, read the <a href="ProgrammersGuide.html">Sphinx-4 Application Programmar's
    Guide</a> for description of how to write a Sphinx-4 application.
    </blockquote>

    <li> <b>Can I use Sphinx-4 in a J2ME device such as a phone or a
    PDA?</b></li>

    <blockquote>
       Probably not. Sphinx-4 requires version 1.4 of the Java
       platform. This is typically not avaiable on smaller devices.
       Also, Sphinx-4 requires more memory than is typically available
       on a J2ME device. Even simple digits recognition will require a
       16Mb heap. Sphinx-4 uses extensive floating point math. Most
       J2ME devices do not have adequate floating point performance
       for Sphinx-4.
    </blockquote>

    <li> <b> Why can't I use Java versions prior to 1.4? </b></li>

    <blockquote>
       Sphinx-4 uses many language and API features of version 1.4 of
       the Java platform including the logging API, the regular
       expressions API, XML parsing APIs and the <b>assert</b>
       facility.
    </blockquote>

    <li> <b> How can I decode .wav files?</b></li>

    <blockquote>
      Take a look at the <a
      href="demo/sphinx/helloworld/README.html">Hello Wave Demo</a>
      program a  command line
      application that transcribes audio in a '.wav' file. <i> Note
      that this demo is not avaiable in the current release</i>
    </blockquote>


    <li> <b>How can I get the recognizer to return partial results
    while a recognition is in process?</b></li>

    <blockquote>
    It is possible to configure Sphinx-4 to generate partial results,
    that is, to inform you periodically as to what it thinks is the
    best possible hypothesis so far, even before the user has stopped
    speaking.
    <p>
    To get this information, add a result listener to the recognizer.
    Your listener will receive a result (which may or not be a final
    result). The hypothesis text can be extracted from the text.
    <p>
    There is a good example of this in sphinx4/tests/live/Live.java

    You can control how often the result listener is fired by setting
    the configuration variable <i>'featureBlockSize'</i> in the decoder. 
    The default setting of 50 indicates that the listener will be 
    called after every 50 frames.
    Since each frame represents 10MS of speech, the listener is called
    every 500ms.
    </blockquote>

    <li> <b> I am having microphone troubles under linux. What can I
    do?</b></li>

    <blockquote>
      There seems to be a significant difference in how different
      versions of the JDK determine which audio resources are
      available on Linux.  This difference seems to affect different
      machines in different ways. We are working with the Java Sound
      folks to get to the root cause of the problem.  In the mean
      time, if you are having trouble getting the demos to work on
      your Linux box try the following:
      <ul>
        <li> Try a native sound recording application (such as
        gnome-sound-recorder) to ensure that you can actually capture
        audio on your system.
        </li>
        <li> Try the <a
        href="../javadoc/edu/cmu/sphinx/tools/audio/doc-files/HowToRunAudioTool.html">AudioTool</a>
        demo to see if you can record audio from a Java application.
        </li>
        <li>
          Check to see if any sound daemons like esd, gstreamer or
          artsd are running. These daemons may have exclusive access to the
          sound device. If any of these are running, kill them
          and try running again.
        </li>
        <li>
         Try switching to another version of the JDK. If JDK 1.4 doesn't
         work, try 1.5 and vice versa.
         </li>
    </blockquote>

    <li> <b>How can I get the N-Best list?</b></li>

    <blockquote>
        The method 'Results.getResultTokens()' returns a list of all
        the tokens associated with paths that have reached the end of
        sentence state.

        This list is not a traditional N-best list of results. Some
        good results are not represented in this list. We also support
        full word lattices that can provide full N-Best lists. We
        currently do not have any user documentation for this,
        however, we will be providing some shortly.
    </blockquote>

    <li> <b>How can I detect and ignore out-of-grammar
    utterances?</b></li>
    <blockquote>
        An out-of-grammar utterance occurs when a speaker says
        something that is not represented by the speech grammar.
        Usually, the recognizer will try to force a match between what
        was said and the grammar.  Many applications need to detect
        when the user has spoken something unexpected.  This is called
        out-of-grammar detection.
        <p>
        The FlatLinguist and the DynamicFlatLinguist can be configured
        to detect out-of-grammar utterances. To do so, set the following
	properties of either linguists:
	<ul>
	<li><i>addOutOfGrammarBranch</i> property to <b>true</b></li>
        <li><i>outOfGrammarProbability</i> to a small value (e.g.
	1E-20), a smaller probability makes it less likely to be recognized
	as out-of-grammar </li>
	<li><i>phoneInsertionProbability</i> to a small value (e.g. 1E-10)</li>
	<li><i>phoneLoopAcousticModel</i> to the acoustic model you are using,
	typically the Wall Street Journal (WSJ) model. WSJ has a wide
	enough range of phones to ensure that rejection works well </li>
	</ul>
        <p>
        When configured this way, the search will look for
        out-of-grammar utterances. If an out of grammar utterance is
        detected, Sphinx-4 will return a result that contains a single
        &lt;unk&gt; word.  Moreover, if you want to know the exact
        sequence of phones that the unknown word is comprised of, you
        can call the method:
        <code>
        Result.getBestToken().getWordUnitPath() 
        </code>
    </blockquote>

    <li> <b>How can I change my language models or grammars at runtime?</b></li>

    <blockquote>
        This is possible, but not entirely convenient.  A new API for
        swapping grammars will be introduced shortly. In the mean time
        this <a href="http://www.speech.cs.cmu.edu/cgi-bin/cmusphinx/twiki/view/Sphinx4/SwappingGrammars">Swapping Grammars page</a> describes two techniques that can be used to swap
        grammars at runtime.
    </blockquote>

    <li> <b>How can I perform word-spotting?</b></li>

    <blockquote>
      There is no support for word-spotting right now. 
    </blockquote>

    <li> <b>Can I use Sphinx-4 to recognize 8khz audio?</b></li>

    <blockquote>
    The current acoustic models that ship with Sphinx-4 are trained on
    16khz data. You can use 8khz input but you will not get very good
    recognition accuracy.
    <p>
    Since a number of people have asked about using 8khz audio input,
    we are looking at training a set of 8khz models. Stay tuned, we'll
    let you know when the new models are available.
    </blockquote>


    <li> <b>Where can I get the audio data used in the regression
    tests?</b></li>

    <blockquote>
    Much of the data audio data used in the regression tests is
    obtained from the <a href="http://wave.ldc.upenn.edu/">Linguistic Data Consortium</a>
    </blockquote>


    <li> <b> How do I use the <b>Result</b> object? </b></li>

    <blockquote>
    A search result typically consists of a number of hypothesis. Each
    hypothesis is represented by a path through the search space. Each
    path is represented by a single token. The token corresponds to
    the end point of the path. Using the token.getPredecessor() method
    it is possible for an application to trace back through the entire
    path to the beginning of the utterance.
    <p>
    Each token along the path contains numerous interesting data that
    can be used by the application including:

    <ul>
    <li> the total path score up to this point (retrieved by getScore())
    <li> A frame number indicating which input frame this token is
      associated with
    <li> A pointer to a state in the search graph corresponding to this
        token (A token may correspond to a word, unit, HMM, HMM state
        or other things). This pointer allows the application to
        retrieve the word, unit, or hmm information associated with
        the token.
    </ul>

        The method getScore() returns the path score for the path
        represented by a particular token This is the total score
        (which includes the language, acoustic and insertion
        components).

        The getAcousticScore returns the acoustic score for a token.
        This score represents how well the associated search state
        matches the input feature for the frame associated with the
        token. This is typically only for 'emitting' states.

        The getLanguageScore() returns the language component of the
        score

        The getInsertionProbability() returns the insertion component
        of the score.

        So the method getScore returns:

        <pre>
        entryScore + getAcousticScore() + getLanguageScore() + getInsertionProbability()
        </pre>

        (where entryScore is token.getPredecessor().getScore() )


    </blockquote>

    <li> <b> How can I train my own acoustic models?</b></li>

    <blockquote>
        Sphinx-4 loads Sphinx-3 acoustic models. These can be trained
        with the Sphinx-3 Trainer called 
        <a href="http://www.speech.cs.cmu.edu/SphinxTrain/"> SphinxTrain</a>
    </blockquote>

    <li> <b> How can I create my own language models?</b></li>

    <blockquote>
     N-Gram language models can be created with the  <a
     href="http://www.speech.cs.cmu.edu/SLM_info.html">CMU Statistical
     Language Modeling (SLM) Toolkit</a>. For more information see
     this <a
     href="../index.html#language_models">Example of building a Language Model</a>.
     language model 
    </blockquote>

    <li> <b> How can I create my own dictionary?</b></li>

    <blockquote>
    Sphinx-4 currentl supports dictionaries in the CMU dictionary
    format.  The CMU dictionary format is described in the <a
    href="../javadoc/edu/cmu/sphinx/linguist/dictionary/FullDictionary.html">FullDictionary</a> javadocs.

    <p>
    Each line of the dictionary specifies the word, followed by spaces
    or tab, followed by the pronuncation (by way of the list of
    phones) of the word. Each word can have more than one
    pronunciations. For example, a digits dictionary will look like:

    <pre>
    ONE HH W AH N
    ONE(2) W AH N
    TWO T UW
    THREE TH R IY
    FOUR F AO R
    FIVE F AY V
    SIX S IH K S
    SEVEN S EH V AH N
    EIGHT EY T
    NINE N AY N
    ZERO Z IH R OW
    ZERO(2) Z IY R OW
    OH OW
    </pre>

    In the above example, the words "one" and "zero" have two
    pronunciations each.  
    <p>
    Some more details on the format of the dictionary can be found
    at the <a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict">CMU
    Pronouncing Dictionary</a> page.
    <p>
    Note that the phones used to define the pronunciation for a word
    can be arbitrary strings. It is important however, that they match
    the units in the acoustic model. If you unpack an acoustic model
    you will find among the many files a file with the suffix ".mdef".
    This file contains a mapping of units to senones (tied gaussian
    mixtures). The first column in this file represent the unit names
    (phone) used by the acoustic model.
    <p>
    Your dictionary should use these units to define the pronunciation
    for a word.
    </blockquote>

    <li> <b> Where can I learn more about the <b> Java Speech
    Grammar Format</b> (JSGF)? </b></li>

    <blockquote>
       A complete description of the JSGF can be found in the <a
       href="http://java.sun.com/products/java-media/speech/forDevelopers/JSGF/">
       JSGF Grammar Format Specification</a>
    </blockquote>

    <li> <b> I've created by own language model. How do I create the
    binary (DMP) form?</b></li>

    <blockquote>
    The tool lm3g2dmp generates a DMP file from an LM in Arpa format
    (which can be generated by the CMU/CU Statistical Language Model
    Toolkit).

    The lm3g2dmp code is available at sf.net, in the module
    share/lm3g2dmp. But the easiest way to get it is via a nightly
    build (a tarball generated nightly from the cvs tree). The site:

    <a
    href="http://cmusphinx.sourceforge.net/webpage/html/download.php#utilities">Sphinx
    utilities </a>

    has a link to this build (and also to the CMU SLM toolkit). Or one
    can retrieve it from the
    <a href="http://cmusphinx.org/download/nightly">Sphinx nightly
    builds</a>.
    </blockquote>

    <li> <b> Where can I find a speech synthesizer for the Java
    platform?</b></li>
    <blockquote>
       The <a href="http://www.sunlabs.com/research/speech/">Speech
       Integration group</a> of Sun Labs has
       released <a href="http://freetts.sourceforge.net">FreeTTS</a>, a speech synthesis system
       written in the Java programming language.
    </blockquote>
</ul>

<hr>
Last update on June 30, 2004.<br>
Copyright 1999-2004 Carnegie Mellon University.<br>
Portions Copyright 2002-2004 Sun Microsystems, Inc.<br>
Portions Copyright 2002-2004 Mitsubishi Electric Research Laboratories.<br>
All Rights Reserved.  Usage is subject to 
<a href="../license.terms">license terms</a>.

</body>

</html>

