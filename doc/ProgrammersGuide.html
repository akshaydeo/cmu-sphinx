<!DOCTYPE html PUBLIC "-//IETF//DTD HTML 2.0//EN">

<!--

Copyright 1999-2004 Carnegie Mellon University.
Portions Copyright 2004 Sun Microsystems, Inc.
Portions Copyright 2004 Mitsubishi Electronic Research Laboratories.
All Rights Reserved.  Use is subject to license terms.

See the file "license.terms" for information on usage and
redistribution of this file, and for a DISCLAIMER OF ALL
WARRANTIES.

-->

<html>
<head>
  <title>Sphinx-4 Programmer's Guide</title>
   <style TYPE="text/css">
     pre { font-size: medium; background: #f0f8ff; padding: 2mm; border-style: ridge ; color: teal}
     code {font-size: medium; color: teal}
     s4keyword { color: red; font-weight: bold }
   </style>
</head>

<body>
  <font face="Arial" size="2">
  <table bgcolor="#99CCFF" width="100%">
    <tr>
      <td align=center width="100%">
        <center><font face="Times New Roman"><h1>Sphinx-4 Programmer's Guide</h1></font></center>
      </td>
    </tr>
  </table>
  <p>
  This tutorial shows you how to write Sphinx-4 applications. We will
  start with an overview of the Sphinx-4 system, with just enough depth
  so that you can use to build applications, but without the full-blown
  details. After that, we will use the Hello World!
  demo as an example to show how a simple application can be written.
  We will then proceed to a more complex example. Consequently,
  this tutorial into the following parts:
  </p>
  <ol>
  <li><a href="#sphinx4basics">Overview of Sphinx-4</a>
     <ul>
     <li><a href="#hmmRecognizers">Overview of an HMM-based Speech Recognizer</a></li>
     <li><a href="#architectureComponents">Sphinx-4 Architecture and Main Components</a></li>
     <li><a href="#configuration">Sphinx-4 Configuration System</a></li>
     </ul>
  <br>
  <li><a href="#helloWorld">Simple Example - Hello World!</a>
     <ul>
     <li><a href="#helloCodeWalk">Code Walk - HelloWorld.java</a>
     <li><a href="#helloConfigWalk">Configuration File Walk - helloworld.config.xml</a>
     <li>Build File Walk - build.xml
     </ul>
  </ol>

  <hr>

  <a name="sphinx4basics"><h2>1. Overview of Sphinx-4</h2></a>

  <p>
  In this section, we will provide an overview of the Sphinx-4 system,
  starting from an overview of HMM-based recognizers. We will highlight
  in <s4keyword>red</s4keyword> those keywords that are critical to 
  understanding Sphinx-4.
  </p>

  <p>
  <h3><a name="hmmRecognizers">Overview of an HMM-based Speech Recognition System</a></h3>
  <p>
  Sphinx-4 is an HMM-based speech recognizer. <s4keyword>HMM</s4keyword>
  stands for Hidden Markov Models, which is a type of statistical model.
  In HMM-based systems,
  each unit of sound (usually called a phoneme) is represented by a statistical
  model that represents the distribution of all the evidence (data) for
  that phoneme. This is called the <s4keyword>acoustic model</s4keyword> 
  for that phoneme.
  The speech signals are first transformed into a sequence of vectors
  that represent certain characteristics of the signal, and the
  parameters of the acoustic model are then estimated using these vectors
  (usually called <s4keyword>features</s4keyword>). This process is called 
  training the acoustic models.
  </p>
  <p>
  During speech recognition, features are derived from the 
  incoming speech (we will use "speech" to mean the same thing as "audio")
  in the same way as in the training process. The component of the recognizer
  that generates these features is called the <s4keyword>front end</s4keyword>.
  These live features are scored against the acoustic model.
  The <s4keyword>score</s4keyword> obtained indicates how 
  likely that a particular set of features (extracted from live
  audio) belongs to the phoneme of the corresponding acoustic model.
  </p>
  <p>
  The process of speech recognition is to find the best possible sequence
  of words (or units) that will fit the given input speech. It is a 
  <s4keyword>search</s4keyword> problem, and in the case of HMM-based 
  recognizers, a graph search problem. The graph represents all possible
  sequences of phonemes in the entire <s4keyword>language</s4keyword>
  of the task under consideration. The graph is typically a very large
  HMM, composed of the HMMs of sound units concatenated in a guided manner,
  as specified by the <s4keyword>grammar</s4keyword> of the task. 
  As an example, lets look at a simple search graph that decodes the words
  "one" and "two":
  </p>
  <img src="1-2-searchgraph.jpg">
  <p>
  Constructing the above graph requires knowledge from various sources.
  It will require a <s4keyword>dictionary</s4keyword>, which maps the word
  "one" to the phonemes W, AX and N, and the word "two" to T and OO.
  It will require the acoustic model to obtain the HMMs for the phonemes
  W, AX, N, T and OO. In Sphinx-4, the task of constructing this search graph
  is done by the <s4keyword>linguist</s4keyword>.
  </p>
  <p>
  Usually, the search graph also has information about how likely certain
  words will occur. This information is supplied by the
  <s4keyword>language model</s4keyword>. Suppose that, in our example,
  the probability of someone saying "one" (e.g., 0.8) is much higher than 
  saying "two" (0.2). Then, in the above graph, the probability of the
  transition between the entry node and the first node of the HMM for W
  will be 0.8, while the probability of the transition between the entry
  node and the first node of the HMM for T will be 0.2. The path to
  "one" will consequently have a higher score.
  </p>
  <p>
  Once this graph is constructed, the sequence of parametrized speech
  signals (i.e., the features) is matched against different paths 
  through the graph to find the best fit. 
  The best fit is usually the least cost or highest
  scoring path, depending on the implementation.
  In Sphinx-4, the task of searching through the graph for the best path
  is done by the <s4keyword>search manager</s4keyword>.
  </p>
  <p>
  As you can see from the above graph, a lot of the nodes have self
  transitions. This can lead to a very large number of possible paths
  through the graph. As a result, finding the best possible path can
  take a very long time. The purpose of the <s4keyword>pruner</s4keyword>
  is to reduce the number of possible paths during the search,
  using heuristics like pruning away the lowest scoring paths.
  </p>
  <p>
  As we described earlier, the input speech signal is transformed into a
  sequence of feature vectors. After the last feature vector is decoded,
  we look at all the paths that have reached the final exit node 
  (the red node). The path with the highest score is the best fit, and a 
  <s4keyword>result</s4keyword> taking all the words of that path is returned.
  </p>
  </p>

  <p>
  <h3><a name="architectureComponents">Sphinx-4 Architecture and Main Components</a></h3>
  <p>
  In this section, we describe the main components of Sphinx-4, and how
  they work together during the recognition process. First of all,
  lets look at the architecture diagram of Sphinx-4. It contains almost
  all the concepts (the words in red) that were introduced in the previous
  section. There are a few additional concepts in the diagram, 
  which we will explain promptly.
  </p>
  <center>
  <img src="../doc-files/architecture.gif">
  </center>

  <p>
  When the recognizer starts up, it constructs the front end, the decoder,
  and the linguist according to the configuration specified by the user.
  These components will in turn construct their own subcomponents. For example,
  the linguist will construct the acoustic model, the dictionary,
  and the language model. It will use the knowledge from these three
  components to contruct a search graph that is appropriate for the task. 
  The decoder will construct the search manager,
  which in turn constructs the scorer, the pruner, and the active list.
  </p>
  <p>
  Most of these components represents interfaces. The search manager,
  linguist, acoustic model, dictionary, language model, active list, scorer,
  pruner, and search graph are all Java interfaces. There can
  be different implementations of these interfaces. For example,
  there are two different implementations of the search manager.
  Then, how does the system know which implementation to use? It is specified
  by the user via the configuration file, an XML-based file that is loaded 
  by the <s4keyword>configuration manager</s4keyword>. In this configuration
  file, the user can also specify the <s4keyword>properties</s4keyword>
  of the implementations. One example of a property is the sample rate 
  of the incoming speech data.
  </p>
  <p>
  The <s4keyword>active list</s4keyword> is a component that requires 
  explanation. Remember we mentioned that there can be many possible paths
  through the search graph. Sphinx-4 currently implements a 
  <s4keyword>token</s4keyword>-passing algorithm. Each time the search arrives
  at the next state in the graph, a token is created. A token points to the 
  previous token, as well as the next state. The active list keeps track of 
  all the current active paths through the search graph by storing the last
  token of each path. A token has the score of the path at that particular
  point in the search. To perform pruning, we simply prune the tokens in the
  active list.
  </p>  
  <p>
  When the application asks the recognizer to perform recognition,
  the search manager will ask the scorer to score each token in the
  active list against the next feature vector obtained from the front end.
  This gives a new score for each of the active paths. The pruner will then 
  prune the tokens (i.e., active paths) using certain heuristics. 
  Each surviving paths will 
  then be expanded to the next states, where a new token will be created 
  for each next state. The process repeats itself until no more feature 
  vectors can be obtained from the front end. This usually means that there
  is no more input speech data. At that point, we look at all paths 
  that have reached the final exit state,
  and return the highest scoring path as the result to the application.
  </p>
  </p>

  <p>
  <h3><a name="configuration">Sphinx-4 Configuration System</a></h3>
  <p>
  The performance of Sphinx-4 critically depends on your task and how
  you configured Sphinx-4 to suit your task. For example, 
  a large vocabulary task needs a different linguist than a small 
  vocabulary task. Your system has to be configured differently
  for the two tasks. This section will not tell you the exact configuration
  for different tasks, which will be dealt with later. Instead, this section
  will introduce you to the configuration mechanism of Sphinx-4, which is
  via an XML-based configuration file. Please click on the document
  <a href="../javadoc/edu/cmu/sphinx/util/props/doc-files/ConfigurationManagement.html">Sphinx-4 Configuration Management</a> to learn how to do this.
  It is important that you read this document before you proceed.
  </p>
  </p>

  <hr>  

  <a name="helloWorld"><h2>2. Simple Example - Hello World!</h2></a>

  <p>
  We will now look at a very simple speech application written using
  Sphinx-4, our Hello World! demo. This application recognizes connected
  digits. As you will see, the code is very simple. The tricky part is
  understanding the configuration, but we will guide you through every step
  of it. Lets look at the code first.
  </p>
  <p>
  <h3><a name="helloCodeWalk">Code Walk - HelloWorld.java</a></h3>
  <p>
  All the source code of the Hello World! demo is in one short file
  <code>sphinx4/demo/sphinx/helloworld/HelloWorld.java</code>:
  </p>
  <pre>
package demo.sphinx.helloworld;

import edu.cmu.sphinx.frontend.util.Microphone;
import edu.cmu.sphinx.recognizer.Recognizer;
import edu.cmu.sphinx.result.Result;
import edu.cmu.sphinx.util.props.ConfigurationManager;
import edu.cmu.sphinx.util.props.PropertyException;

import java.io.File;
import java.io.IOException;
import java.net.URL;

/**
 * A simple HelloWorld demo showing a simple speech application 
 * built using Sphinx-4.
 */
public class HelloWorld {

    /**
     * Main method for running the HelloWorld demo.
     */
    public static void main(String[] args) {
        try {
            URL url;
            if (args.length > 0) {
                url = new File(args[0]).toURI().toURL();
            } else {
                url = HelloWorld.class.getResource("helloworld.config.xml");
            }

            ConfigurationManager cm = new ConfigurationManager(url);

	    Recognizer recognizer = (Recognizer) cm.lookup("recognizer");
	    Microphone microphone = (Microphone) cm.lookup("microphone");

            recognizer.allocate();

	    if (microphone.startRecording()) {
		System.out.println
		    ("Say any digit(s): e.g. \"two oh oh four\", " +
		     "\"three six five\".");

		while (true) {
		    System.out.println
			("Start speaking. " + 
			 "Press Ctrl-C or say 'good bye' to quit.");

		    Result result = recognizer.recognize();

		    if (result != null) {
			String resultText = result.getBestResultNoFiller();
			System.out.println("You said: " + resultText + "\n");

			if (resultText.equals("good bye")) {
			    microphone.stopRecording();
			    recognizer.deallocate();
			    System.exit(0);
			}
		    } else {
			System.out.println("I can't hear what you said.\n");
		    }
		}
	    } else {
	        System.out.println("Cannot start microphone.");
		recognizer.deallocate();
		System.exit(1);
	    }
        } catch (IOException e) {
            System.err.println("Problem when loading HelloWorld: " + e);
            e.printStackTrace();
        } catch (PropertyException e) {
            System.err.println("Problem configuring HelloWorld: " + e);
            e.printStackTrace();
        } catch (InstantiationException e) {
            System.err.println("Problem creating HelloWorld: " + e);
            e.printStackTrace();
        }
    }
}
</pre>

  <p>
  This demo imports several important classes in Sphinx-4:
  <br>
  <code>
<br><a href="../javadoc/edu/cmu/sphinx/recognizer/Recognizer.html">edu.cmu.sphinx.recognizer.Recognizer</a>
<br><a href="../javadoc/edu/cmu/sphinx/result/Result.html">edu.cmu.sphinx.result.Result</a>
<br><a href="../javadoc/edu/cmu/sphinx/util/props/ConfigurationManager.html">edu.cmu.sphinx.util.props.ConfigurationManager</a>
  </code>
  </p>
  <p>
  The <code>Recognizer</code> is the main class any application should
  interact with (refer also to the architecture diagram above).
  The <code>Result</code> is returned by the Recognizer to the application
  after recognition completes. The <code>ConfigurationManager</code>
  creates the entire Sphinx-4 system according to the configuration specified
  by the user.
  </p>
  <p>
  Lets look at the <code>main()</code> method. The first few
  lines creates the URL of the XML-based configuration file.
  A <code>ConfigurationManager</code> is then created using that URL.
  The ConfigurationManager then reads in the
  file internally. Since the configuration file specifies the components 
  <code>"recognizer"</code> and <code>"microphone"</code> (we will look
  at the configuration file next),
  we perform a <a href="../javadoc/edu/cmu/sphinx/util/props/ConfigurationManager.html#lookup(java.lang.String)"><code>lookup()</code></a> of these components
  in the ConfigurationManager to obtain these components. The <a href="../javadoc/edu/cmu/sphinx/recognizer/Recognizer.html#allocate()"><code>allocate()</code></a> method of the Recognizer is then called to allocate the resources
  need for the recognizer.
  </p>
  <p>
  Once all the necessary components are created, we can start running the demo.
  We first ask the Microphone to
  <a href="../javadoc/edu/cmu/sphinx/frontend/util/Microphone.html#startRecording()"><code>startRecording</code></a>, i.e., we turn on the microphone.
  After the microphone is turned on successfully, the demo goes into a
  loop that tries to recognize what the user is saying, using the
  <a href="../javadoc/edu/cmu/sphinx/recognizer/Recognizer.html#recognize()">
  <code>Recognizer.recognize()</code></a> method. Note that endpointing 
  is used here to decide when an utterance starts and ends.
  Once an utterance is recognized, the recognized text,
  which is returned by the method
  <a href="../javadoc/edu/cmu/sphinx/result/Result.html#getBestResultNoFiller()">
  <code>Result.getBestResultNoFiller()</code></a>, is printed out. 
  If the user said "good bye", the microphone will stop recording, 
  the recognizer deallocated, and the program exits.
  It is generally a good practice to call the method
  <a href="../javadoc/edu/cmu/sphinx/recognizer/Recognizer.html#deallocate()">
  <code>deallocate()</code></a> after the work is done to release all the
  resources. If the Recognizer recognized nothing (i.e., <code>result</code> is
  null), then it will print out a message saying that. Finally, if the
  demo program cannot turn on the microphone in the first place, the
  Recognizer will be deallocated, and the program exits.
  </p>
  <p>
  Note that several exceptions were being caught. First of all,
  the IOException is thrown by the <a href="../javadoc/edu/cmu/sphinx/util/props/ConfigurationManager.html#ConfigurationManager(java.net.URL)">constructor</a>
  of the ConfigurationManager</a> and the Recognizer.allocate() method.
  The <a href="../javadoc/edu/cmu/sphinx/util/props/PropertyException.html">
  PropertyException</a> is thrown again by the constructor, and by the
  <code>lookup()</code> method, of the ConfigurationManager.
  These exceptions should be caught and handled appropriately.
  </p>
  <p>
  Hopefully, by this point, you will have some idea of how to write a simple
  Sphinx-4 application. We will now turn to the harder part, understanding
  the various components necessary to create a connected-digits recognizer.
  These components are specified in the configuration file, which we will
  now explain in depth.
  </p>
  </p>
  <p>
  <h3><a name="helloConfigWalk">Configuration File Walk - helloworld.config.xml</a></h3>

  </p>

  (to be continued)


  <pre>ant all</pre>

  </font>
</body>

</html>
