High Level Design
=================
Here are a loose collection of design notes for the A.M. I am going to
start constructing the interfaces and high level classes.

Some high level design issues:

 - Many separate objects are maintained in pools. These pools need to be
   constructed, objects need to be placed in pools, pools need to be
   efficiently accessed.

   A resource pool class will be used to manage these pools. There
   will be a resource pool created for each type of shared object
   (senones, senone sequences, means, variance ...). These pools will
   be maintained in the AcousitModel class. Each of these items that
   are in the pool have an associated ID. 

   For example, the senone will be described as a set of IDs to the
   various subcomponents (means for instance). The senone description
   in the acoustic model database will include the IDs for the set of
   means to use for the senone. The loader will retrieve the means
   from the means pool using these IDs as keys into the pool and place
   references to these means in the newly constructed Senone

    The resource pool is fairly straightforward signature:

    class ResourcePool {
	public void add(int id, Object pooledObject);
	public Object get(int id);
    }

 - Since Senones are shared by a number of HMMs, once a senone is
   scored for a particular feature, the score should be resused to
   eliminate the expense of recalulating the score. There are a number
   of ways this could be managed. The simplest method is for each
   Senone to keep a copy of the most recent score calculated along
   with a reference to the Feature that is associated with the score.
   When a feature is scored against a senone, the senone can first check 
   to see if the new feature matches the feature associated with the
   cached score and if so, simple return the score instead of
   recalculating the score.

 - Even though the Acoustic Model can be quite large, (on the order of
   50MB for large vocabulary), I propose that, at least for the first
   implmentation, the A.M. be kept in memory.  The interfaces to the 
   A.M will certainly allow us to implement a paging or memory-mapped
   file versions of the A.M., but I recommend that defer those designs
   until needed.

 - Building Senone Sequences - As the set of HMMs are read in from the
   database, common senone sequences can be identified and shared in
   order to reduce memory consumption.
   

 - Building Composite Senone Sequences - Need the capability of
   looking up HMMs that match a particular context and position


 - There are likely to be several versions of the AcousticModel
   database. The A.M. will provide separate database loaders for each
   version.  The initial loader will load a sphinx3 DB as seen in
   "modelsetc.tar". 

   When Rita provides a new model, in the updated format, a new model
   loader will be written. (Note that if I get a model early, I can
   skip the writing of the loader for the old sphinx3 format).


Acoustic Model Life Cycle:

    init:
    	The recognizer (or some other high level software), calls
	AcousticModel.initAcousticModel to associate a recognizer
	context with a particular acoustic model This has the affect
	of loading the acoustic model.  Calls are made to:
		AcousticModel.initAcousticModel()
		AcousticModel.getAcousticModel()


    prep:
    	Even though this has not been to well defined, I would guess
	that during startup, some part of the system (the language
	model perhaps?) will query the AcousticModel for HMMs for
	every possible context in the system. (This is to build up a
	lex tree with each lex node pointing to an appropriate HMM).

	Also (as well, not yet defined to well), composite senones
	(and hmms pointing to them) are created for phones that have
	incomplete contexts (beginning and end of words).  (Note that
	this cannot be done completely internally to the A.M since it
	requires a dictionary to find those end-of-word phones. To
	support this, the A.M.should provide an interface that will
	all querying of phones by context and position.

    Once per frame:
    	All senone scores are reset. (This may not be necessary,
	depending on the method used to cache senone scores). See the
	discussion later on. Calls are made to:
		AcousticModel.resetSenones();
		senone.reset();	// interface not defined yet

	The "Mystery Layer" selects a set of senones from the HMMs and
	extracts the senones, and transition matrix for the Hmm. Calls
	are made to:
		HMM.getSenoneSequence()
		HMM.getTransitionMatrix()
		SenoneSequence.getSenones(),

	The search selects a set of active senones and sends them to
	an acoustic scorer. The acoustic scorer iterates through the
	set of senones and scores each one. A senone keeps track of
	its own score, and if the senone has already been scored
	during this frame, that score is returned instead of
	recalculating the score.  

    On Occasion:
    	Some Acoustic model adaptor may run and decide to change
	some  acoustic model settings.  We don't have good
	requirements for this yet, so we won't do anything about it
	right now.

    On exit:
    	If the acoustic model has been adapted, we may need to save
	the adaptation so that it can be used again.  No strong
	requirments yet for this, so we won't do anything about it
	right now.
    	
Note that the Acoustic Model life cycle for the trainer is likely to
be quite different, but we are not going to do anything about
acoustic model training right now.


Loading the Acoustic Mode
==========================
We can write a loader that will load up the current sphinx3 acoustic
model.  The acoustic model is spread out over a few files. The main issue
with writing a sphinx3 loader will be dealing with byteswapping
issues.

     model_architecture/comm_cont.6000.mdef - This consists of filler
     phones, context independent phones and context dependent phones.
     This file is used to create the HMMs. Bulk of the file consists
     of lines of the form:

        AH  EH  ER s    n/a   13    586    614    647 N

	This consists of:

	base phone
	Left context
	Right context
	Word position - do we need to store this?
	Senone states
	HMM ID is inferred from file position

	modelsetc/6k8gau.comm.quant - subvq stuff, don't need this now

	// these files contain the data for the individual senones
	// format is binary but fairly straight forward.
	// unfortunately, the byte order is little-endian, which means
	// we would have to to a byteswapping thing which may be ugly
	// I assume that the FP values are IEEE754 floating point but
	// I can't tell for sure.

	model_parameters/comm_cont.cd_continuous/means
	model_parameters/comm_cont.cd_continuous/variances
	model_parameters/comm_cont.cd_continuous/transition_matrices
	model_parameters/comm_cont.cd_continuous/mixture_weights




Adaptations to the file format
==============================
HMM File:
 For each HMM:
    ID (can be implied by file position)
    base unit  (string)
    NumLeft left_unit_0 left_unit_1 ...
    NumRight right_unit_0 right_unit_1 ...
    context  (equivalent to sphinx3 word-position)
    NumStates
    senone_0 senone_1 senone_2 senone_3 ...
    tmat[0][0] tmat[0][1] ...  (since its a sparse matrix, some fields ommitted)

 For Each senone
     ID (can be implied by file position)
     density mixw_0 mixw_0 ...		// mixture weights
     mean_id mtm_id mtv_id var_id vtm_id

 For Means:
     ID veclen mean_0 mean_1 ...
     ID veclen mean_0 mean_1 ...
     ID veclen mean_0 mean_1 ...

 For MeanTransformationMatrix (mtm):
     ID veclen mtm[0][0] mtm[0][1] ...
     ID veclen mtm[0][0] mtm[0][1] ...
     ID veclen mtm[0][0] mtm[0][1] ...

 For MeansTransformationVector (mtv):
     ID veclen mtv_0 mtv_1 ...
     ID veclen mtm[0][0] mtm[0][1] ...
     ID veclen mtm[0][0] mtm[0][1] ...

 For Variance:
     ID veclen var_0 var_1 ...
     ID veclen var_0 var_1 ...
     ID veclen var_0 var_1 ...

 For VarianceTransformationMatrix (vtm):
     ID veclen vtm[0][0] vtm[0][1] ...
     ID veclen vtm[0][0] vtm[0][1] ...
     ID veclen vtm[0][0] vtm[0][1] ...
 	
Initial format preferably in ASCII. We can convert to binary later on
as necessary.  Separate files for each ID'd element are fine, these
can be combined into a single file later on.

