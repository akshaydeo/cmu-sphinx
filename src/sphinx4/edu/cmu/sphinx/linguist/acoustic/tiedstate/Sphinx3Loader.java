/*
 * Copyright 1999-2004 Carnegie Mellon University.  
 * Portions Copyright 2004 Sun Microsystems, Inc.  
 * Portions Copyright 2004 Mitsubishi Electric Research Laboratories.
 * All Rights Reserved.  Use is subject to license terms.
 * 
 * See the file "license.terms" for information on usage and
 * redistribution of this file, and for a DISCLAIMER OF ALL 
 * WARRANTIES.
 *
 */
package edu.cmu.sphinx.linguist.acoustic.tiedstate;

// Placeholder for a package import

import edu.cmu.sphinx.linguist.acoustic.*;
import static edu.cmu.sphinx.linguist.acoustic.tiedstate.Pool.Feature.*;
import edu.cmu.sphinx.util.ExtendedStreamTokenizer;
import edu.cmu.sphinx.util.LogMath;
import edu.cmu.sphinx.util.Utilities;
import edu.cmu.sphinx.util.props.*;

import java.io.*;
import java.util.LinkedHashMap;
import java.util.Map;
import java.util.Properties;
import java.util.logging.Level;
import java.util.logging.Logger;

/**
 * Loads a tied-state acoustic model generated by the Sphinx-3 trainer.
 * <p>
 * The acoustic model should be packaged in a JAR file or should be unpacked on
 * disk. The dictionary and language model files are not required to be in the
 * package. You can specify their locations separately. Properties of the model
 * should be either configure in a config file or stored with the model in
 * "model.props" text file. The "model.props" has the priority over the config
 * file. It is a file of key-value pairs, loadable as a Java Properties file. It
 * should minimally contain the following properties:
 * <ul>
 * <li><b>dataLocation</b> - this specifies the directory where the actual model
 * data files are, <i>relative to the model implementation class</i></li>
 * <li><b>modelDefinition</b> - this specifies the location where the model
 * definition file is, <i>relative to the model implementation class</i></li>
 * </ul>
 * The actual model data files are named "means", "variances",
 * "transition_matrices", "mixture_weights" for binary versions, or prepended
 * with ".ascii" for the ASCII versions.
 * </p>
 * <p>
 * As an example, lets look at the Wall Street Journal acoustic model JAR file,
 * which is located at the <code>sphinx4/lib</code> directory. If you run
 * <code>"jar tvf lib/WSJ_8gau_13dCep_16k_40mel_130Hz_6800Hz.jar"</code>, you
 * will find that its internal structure looks roughly like:
 * <p/>
 * <pre>
 * WSJ_8gau_13dCep_16k_40mel_130Hz_6800Hz.jar
 *   |
 *   +- edu
 *       |
 *       +- cmu
 *           |
 *           +- sphinx
 *               |
 *               +- model
 *                   |
 *                   + acoustic
 *                      |
 *                      +- model.props
 *                      |
 *                      +- WSJ_8gau_13dCep_16k_40mel_130Hz_6800Hz.class
 *                      |
 *                      +- WSJLoader.class
 *                      |
 *                      +- cd_continuous_8gau
 *                      |   |
 *                      |   +- means
 *                      |   +- variances
 *                      |   +- mixture_weights
 *                      |   +- transition_matrices
 *                      |
 *                      +- dict
 *                      |   |
 *                      |   +- alpha.dict
 *                      |   +- cmudict.0.6d
 *                      |   +- digits.dict
 *                      |   +- fillerdict
 *                      |
 *                      +- etc
 *                          |
 *                          +- WSJ_clean_13dCep_16k_40mel_130Hz_6800Hz.4000.mdef
 *                          +- WSJ_clean_13dCep_16k_40mel_130Hz_6800Hz.ci.mdef
 *                          +- variables.def
 * </pre>
 * <p/>
 * The model.props file looks like (note how the 'dataLocation' and
 * 'modelDefinition' properties are defined relative to the
 * WSJ_clean_13dCep_16k_40mel_130Hz_6800Hz.class):
 * </p>
 * <p>
 * <p/>
 * <pre>
 * description = Wall Street Journal acoustic models
 * isBinary = true
 * featureType = cepstra_delta_doubledelta
 * vectorLength = 39
 * sparseForm = false
 * &lt;p/&gt;
 * numberFftPoints = 512
 * filters = 40
 * gaussians = 8
 * maxFreq = 6800
 * minFreq. = 130
 * sampleRate = 16000
 * <p/>
 * dataLocation = cd_continuous_8gau
 * modelDefinition = etc/WSJ_clean_13dCep_16k_40mel_130Hz_6800Hz.4000.mdef
 * </pre>
 * <p/>
 * <p>
 * Note that although most of the properties of this class are already defined
 * in the model.props file, it is still possible (but not recommended) to
 * override those values by specifying them in the configuration file.
 * </p>
 */
@SuppressWarnings({"JavaDoc", "JavaDoc", "JavaDoc"})
public class Sphinx3Loader implements Loader {

    /**
     * The log math component for the system.
     */
    @S4Component(type = LogMath.class)
    public final static String PROP_LOG_MATH = "logMath";

    /**
     * The unit manager
     */
    @S4Component(type = UnitManager.class)
    public final static String PROP_UNIT_MANAGER = "unitManager";

    /**
     * Specifies whether the model to be loaded is in ASCII or binary format
     */
    @S4Boolean(defaultValue = true)
    public final static String PROP_IS_BINARY = "isBinary";

    /**
     * The name of the model definition file (contains the HMM data)
     */
    @S4String(mandatory = false, defaultValue = "mdef")
    public final static String PROP_MODEL = "modelDefinition";

    /**
     * Subfolder where the acoustic model can be found
     */
    @S4String(mandatory = false, defaultValue = "data")
    public final static String PROP_DATA_LOCATION = "dataLocation";

    /**
     * The SphinxProperty for the name of the acoustic properties file.
     */
    @S4String(defaultValue = "model.props")
    public final static String PROP_PROPERTIES_FILE = "propertiesFile";

    /**
     * The SphinxProperty for the length of feature vectors.
     */
    @S4Integer(defaultValue = 39)
    public final static String PROP_VECTOR_LENGTH = "vectorLength";

    /**
     * The SphinxProperty specifying whether the transition matrices of the
     * acoustic model is in sparse form, i.e., omitting the zeros of the
     * non-transitioning states.
     */
    @S4Boolean(defaultValue = true)
    public final static String PROP_SPARSE_FORM = "sparseForm";

    /**
     * The SphinxProperty specifying whether context-dependent units should be used.
     */
    @S4Boolean(defaultValue = true)
    public final static String PROP_USE_CD_UNITS = "useCDUnits";

    /**
     * Mixture component score floor.
     */
    @S4Double(defaultValue = 0.0f)
    public final static String PROP_MC_FLOOR = "MixtureComponentScoreFloor";

    /**
     * Variance floor.
     */
    @S4Double(defaultValue = 0.0001f)
    public final static String PROP_VARIANCE_FLOOR = "varianceFloor";

    /**
     * Mixture weight floor.
     */
    @S4Double(defaultValue = 1e-7f)
    public final static String PROP_MW_FLOOR = "mixtureWeightFloor";

    protected final static String FILLER = "filler";
    protected final static String SILENCE_CIPHONE = "SIL";
    protected final static int BYTE_ORDER_MAGIC = 0x11223344;

    /**
     * Supports this version of the acoustic model
     */
    public final static String MODEL_VERSION = "0.3";
    protected final static int CONTEXT_SIZE = 1;
    private Pool<float[]> meansPool;
    private Pool<float[]> variancePool;
    private Pool<float[][]> matrixPool;
    private Pool<float[][]> meanTransformationMatrixPool;
    private Pool<float[]> meanTransformationVectorPool;
    private Pool<float[][]> varianceTransformationMatrixPool;
    private Pool<float[]> varianceTransformationVectorPool;
    private Pool<float[]> mixtureWeightsPool;
    private Pool<Senone> senonePool;
    private float[][] transformMatrix;
    private Map<String, Unit> contextIndependentUnits;
    private HMMManager hmmManager;
    private LogMath logMath;
    private UnitManager unitManager;
    private Properties properties;
    private boolean swap;
    protected final static String DENSITY_FILE_VERSION = "1.0";
    protected final static String MIXW_FILE_VERSION = "1.0";
    protected final static String TMAT_FILE_VERSION = "1.0";
    protected final static String TRANSFORM_FILE_VERSION = "0.1";
    // --------------------------------------
    // Configuration variables
    // --------------------------------------
    protected Logger logger;
    private boolean binary;
    protected boolean sparseForm;
    private int vectorLength;
    private String model;
    private String dataDir;
    private String propsFile;
    private float distFloor;
    private float mixtureWeightFloor;
    private float varianceFloor;
    private boolean useCDUnits;
    private boolean loaded;

    public Sphinx3Loader(String propsFile, LogMath logMath, UnitManager unitManager,
                         boolean isBinary, boolean sparseForm, int vectorLength, String model, String dataDir,
                         float distFloor, float mixtureWeightFloor, float varianceFloor, boolean useCDUnits) {

        this.logger = Logger.getLogger(getClass().getName());

        this.propsFile = propsFile;
        loadProperties();

        this.logMath = logMath;
        this.unitManager = unitManager;
        this.binary = isBinary;
        this.sparseForm = sparseForm;
        this.vectorLength = vectorLength;
        this.model = model;
        this.dataDir = dataDir;
        this.distFloor = distFloor;
        this.mixtureWeightFloor = mixtureWeightFloor;
        this.varianceFloor = varianceFloor;
        this.useCDUnits = useCDUnits;
    }

    public Sphinx3Loader() {

    }

    @Override
    public void newProperties(PropertySheet ps) throws PropertyException {
        logger = ps.getLogger();

        propsFile = ps.getString(PROP_PROPERTIES_FILE);
        loadProperties();

        logMath = (LogMath) ps.getComponent(PROP_LOG_MATH);
        unitManager = (UnitManager) ps.getComponent(PROP_UNIT_MANAGER);

        String isBinary = (String) properties.get(PROP_IS_BINARY);
        binary = isBinary != null ? Boolean.valueOf(isBinary) : ps.getBoolean(PROP_IS_BINARY);

        String isSparse = (String) properties.get(PROP_SPARSE_FORM);
        sparseForm = isSparse != null ? Boolean.valueOf(isSparse) : ps.getBoolean(PROP_SPARSE_FORM);

        String length = (String) properties.get(PROP_VECTOR_LENGTH);
        vectorLength = length != null ? Integer.parseInt(length) : ps.getInt(PROP_VECTOR_LENGTH);

        String mdef = (String) properties.get(PROP_MODEL);
        model = mdef != null ? mdef : ps.getString(PROP_MODEL);

        String dataLocation = (String) properties.get(PROP_DATA_LOCATION);
        dataDir = dataLocation != null ? dataLocation : ps.getString(PROP_DATA_LOCATION);
        dataDir = dataDir + '/';

        distFloor = ps.getFloat(PROP_MC_FLOOR);
        mixtureWeightFloor = ps.getFloat(PROP_MW_FLOOR);
        varianceFloor = ps.getFloat(PROP_VARIANCE_FLOOR);
        useCDUnits = ps.getBoolean(PROP_USE_CD_UNITS);
    }

    // This function is a bit different from the
    // ConfigurationManagerUtils.getResource
    // for compatibility reasons. By default it looks for the resources, not
    // for the files.
    private InputStream getDataStream(String path) {

        if (path.startsWith("file:")) {
            try {
                return new FileInputStream(path.substring(5));
            } catch (Exception e) {
                return null;
            }
        }
        return getClass().getResourceAsStream(path);
    }

    private void loadProperties() {
        if (properties == null) {
            properties = new Properties();
            try {
                InputStream stream = getDataStream(propsFile);
                if (stream != null)
                    properties.load(stream);
            } catch (IOException ioe) {
                ioe.printStackTrace();
            }
        }
    }

    @Override
    public void load() throws IOException {
        if (!loaded) {
            // TODO: what is this all about?
            hmmManager = new HMMManager();
            contextIndependentUnits = new LinkedHashMap<String, Unit>();
            // dummy pools for these elements
            meanTransformationMatrixPool = createDummyMatrixPool("meanTransformationMatrix");
            meanTransformationVectorPool = createDummyVectorPool("meanTransformationMatrix");
            varianceTransformationMatrixPool = createDummyMatrixPool("varianceTransformationMatrix");
            varianceTransformationVectorPool = createDummyVectorPool("varianceTransformationMatrix");
            transformMatrix = null;
            // do the actual acoustic model loading
            loadModelFiles(model);
            loaded = true;
        }
    }

    /**
     * Return the HmmManager.
     *
     * @return the hmmManager
     */
    protected HMMManager getHmmManager() {
        return hmmManager;
    }

    /**
     * Return the MatrixPool.
     *
     * @return the matrixPool
     */
    protected Pool<float[][]> getMatrixPool() {
        return matrixPool;
    }

    /**
     * Return the MixtureWeightsPool.
     *
     * @return the mixtureWeightsPool
     */
    protected Pool<float[]> getMixtureWeightsPool() {
        return mixtureWeightsPool;
    }

    /**
     * Return the acoustic model properties.
     *
     * @return the acoustic model properties
     */
    protected Properties getProperties() {
        if (properties == null) {
            loadProperties();
        }
        return properties;
    }

    /**
     * Loads the AcousticModel from a directory in the file system.
     *
     * @param modelName the name of the acoustic model; if null we just load from the default location
     * @throws java.io.IOException
     */
    private void loadModelFiles(String modelName) throws IOException {

        logger.config("Loading Sphinx3 acoustic model: " + modelName);
        logger.config("    modellName: " + model);
        logger.config("    dataDir   : " + dataDir);

        if (binary) {
            meansPool = loadDensityFileBinary(dataDir + "means", -Float.MAX_VALUE);
            variancePool = loadDensityFileBinary(dataDir + "variances", varianceFloor);
            mixtureWeightsPool = loadMixtureWeightsBinary(dataDir + "mixture_weights", mixtureWeightFloor);
            matrixPool = loadTransitionMatricesBinary(dataDir + "transition_matrices");
            transformMatrix = loadTransformMatrix(dataDir + "feature_transform");
        } else {
            meansPool = loadDensityFileAscii(dataDir + "means.ascii", -Float.MAX_VALUE);
            variancePool = loadDensityFileAscii(dataDir + "variances.ascii", varianceFloor);
            mixtureWeightsPool = loadMixtureWeightsAscii(dataDir + "mixture_weights.ascii", mixtureWeightFloor);
            matrixPool = loadTransitionMatricesAscii(dataDir + "transition_matrices.ascii");
        }
        senonePool = createSenonePool(distFloor, varianceFloor);
        // load the HMM model file
        InputStream modelStream = getDataStream(model);
        if (modelStream == null) {
            throw new IOException("can't find model " + model);
        }
        loadHMMPool(useCDUnits, modelStream, model);
    }

    @Override
    public Map<String, Unit> getContextIndependentUnits() {
        return contextIndependentUnits;
    }

    /**
     * Creates the senone pool from the rest of the pools.
     *
     * @param distFloor     the lowest allowed score
     * @param varianceFloor the lowest allowed variance
     * @return the senone pool
     */
    private Pool<Senone> createSenonePool(float distFloor, float varianceFloor) {
        Pool<Senone> pool = new Pool<Senone>("senones");
        int numMixtureWeights = mixtureWeightsPool.size();

        int numMeans = meansPool.size();
        int numVariances = variancePool.size();
        int numGaussiansPerSenone = mixtureWeightsPool.getFeature(NUM_GAUSSIANS_PER_STATE, 0);
        int numSenones = mixtureWeightsPool.getFeature(NUM_SENONES, 0);
        int whichGaussian = 0;

        logger.fine("NG " + numGaussiansPerSenone);
        logger.fine("NS " + numSenones);
        logger.fine("NMIX " + numMixtureWeights);
        logger.fine("NMNS " + numMeans);
        logger.fine("NMNS " + numVariances);

        assert numGaussiansPerSenone > 0;
        assert numMixtureWeights == numSenones;
        assert numVariances == numSenones * numGaussiansPerSenone;
        assert numMeans == numSenones * numGaussiansPerSenone;

        for (int i = 0; i < numSenones; i++) {
            MixtureComponent[] mixtureComponents = new MixtureComponent[numGaussiansPerSenone];
            for (int j = 0; j < numGaussiansPerSenone; j++) {
                mixtureComponents[j] = new MixtureComponent(
                        logMath,
                        meansPool.get(whichGaussian),
                        meanTransformationMatrixPool.get(0),
                        meanTransformationVectorPool.get(0),
                        variancePool.get(whichGaussian),
                        varianceTransformationMatrixPool.get(0),
                        varianceTransformationVectorPool.get(0),
                        distFloor,
                        varianceFloor);

                whichGaussian++;
            }

            Senone senone = new GaussianMixture(logMath, mixtureWeightsPool.get(i), mixtureComponents, i);

            pool.put(i, senone);
        }
        return pool;
    }

    /**
     * Loads the sphinx3 density file, a set of density arrays are created and
     * placed in the given pool.
     *
     * @param path  the name of the data
     * @param floor the minimum density allowed
     * @return a pool of loaded densities
     * @throws FileNotFoundException if a file cannot be found
     * @throws IOException           if an error occurs while loading the data
     */
    private Pool<float[]> loadDensityFileAscii(String path, float floor)
            throws IOException {
        logger.fine("Loading density file from: " + path);
        InputStream inputStream = getDataStream(path);
        if (inputStream == null) {
            throw new FileNotFoundException("Error trying to read file " + path);
        }

        // 'false' argument refers to EOL is insignificant
        ExtendedStreamTokenizer est = new ExtendedStreamTokenizer(inputStream, '#', false);
        Pool<float[]> pool = new Pool<float[]>(path);
        est.expectString("param");
        int numStates = est.getInt("numStates");
        int numStreams = est.getInt("numStreams");
        int numGaussiansPerState = est.getInt("numGaussiansPerState");
        pool.setFeature(NUM_SENONES, numStates);
        pool.setFeature(NUM_STREAMS, numStreams);
        pool.setFeature(NUM_GAUSSIANS_PER_STATE, numGaussiansPerState);
        for (int i = 0; i < numStates; i++) {
            est.expectString("mgau");
            est.expectInt("mgau index", i);
            est.expectString("feat");
            est.expectInt("feat index", 0);
            for (int j = 0; j < numGaussiansPerState; j++) {
                est.expectString("density");
                est.expectInt("densityValue", j);
                float[] density = new float[vectorLength];
                for (int k = 0; k < vectorLength; k++) {
                    density[k] = est.getFloat("val");
                    if (density[k] < floor) {
                        density[k] = floor;
                    }
                    // System.out.println(" " + i + " " + j + " " + k + " " + density[k]);
                }
                int id = i * numGaussiansPerState + j;
                pool.put(id, density);
            }
        }
        est.close();
        return pool;
    }

    /**
     * Loads the sphinx3 density file, a set of density arrays are created and
     * placed in the given pool.
     *
     * @param path  the name of the data
     * @param floor the minimum density allowed
     * @return a pool of loaded densities
     * @throws FileNotFoundException if a file cannot be found
     * @throws IOException           if an error occurs while loading the data
     */
    private Pool<float[]> loadDensityFileBinary(String path, float floor)
            throws IOException {
        Properties props = new Properties();
        int blockSize = 0;

        DataInputStream dis = readS3BinaryHeader(path, props);

        String version = props.getProperty("version");

        if (version == null || !version.equals(DENSITY_FILE_VERSION)) {
            throw new IOException("Unsupported version in " + path);
        }

        String checksum = props.getProperty("chksum0");
        boolean doCheckSum = (checksum != null && checksum.equals("yes"));

        int numStates = readInt(dis);
        int numStreams = readInt(dis);
        int numGaussiansPerState = readInt(dis);

        int[] vectorLength = new int[numStreams];
        for (int i = 0; i < numStreams; i++) {
            vectorLength[i] = readInt(dis);
        }

        int rawLength = readInt(dis);

        //System.out.println("Nstates " + numStates);
        //System.out.println("Nstreams " + numStreams);
        //System.out.println("NgaussiansPerState " + numGaussiansPerState);
        //System.out.println("vectorLength " + vectorLength.length);
        //System.out.println("rawLength " + rawLength);

        for (int i = 0; i < numStreams; i++) {
            blockSize += vectorLength[i];
        }

        assert rawLength == numGaussiansPerState * blockSize * numStates;
        assert numStreams == 1;

        Pool<float[]> pool = new Pool<float[]>(path);
        pool.setFeature(NUM_SENONES, numStates);
        pool.setFeature(NUM_STREAMS, numStreams);
        pool.setFeature(NUM_GAUSSIANS_PER_STATE, numGaussiansPerState);

        for (int i = 0; i < numStates; i++) {
            for (int j = 0; j < numStreams; j++) {
                for (int k = 0; k < numGaussiansPerState; k++) {
                    float[] density = readFloatArray(dis, vectorLength[j]);
                    floorData(density, floor);
                    pool.put(i * numGaussiansPerState + k, density);
                }
            }
        }

        int checkSum = readInt(dis);
        // BUG: not checking the check sum yet.
        dis.close();
        return pool;
    }

    /**
     * Reads the S3 binary header from the given location + path. Adds header
     * information to the given set of properties.
     *
     * @param path  the name of the file
     * @param props the properties
     * @return the input stream positioned after the header
     * @throws IOException on error
     */
    protected DataInputStream readS3BinaryHeader(String path, Properties props)
            throws IOException {

        InputStream inputStream = getDataStream(path);

        if (inputStream == null) {
            throw new IOException("Can't open " + path);
        }
        DataInputStream dis = new DataInputStream(new BufferedInputStream(inputStream));
        String id = readWord(dis);
        if (!id.equals("s3")) {
            throw new IOException("Not proper s3 binary file " + path);
        }
        String name;
        while ((name = readWord(dis)) != null) {
            if (!name.equals("endhdr")) {
                String value = readWord(dis);
                props.setProperty(name, value);
            } else {
                break;
            }
        }
        int byteOrderMagic = dis.readInt();
        if (byteOrderMagic == BYTE_ORDER_MAGIC) {
            // System.out.println("Not swapping " + path);
            swap = false;
        } else if (byteSwap(byteOrderMagic) == BYTE_ORDER_MAGIC) {
            // System.out.println("SWAPPING " + path);
            swap = true;
        } else {
            throw new IOException("Corrupt S3 file " + path);
        }
        return dis;
    }

    /**
     * Reads the next word (text separated by whitespace) from the given stream.
     *
     * @param dis the input stream
     * @return the next word
     * @throws IOException on error
     */
    String readWord(DataInputStream dis) throws IOException {
        StringBuilder sb = new StringBuilder();
        char c;
        // skip leading whitespace
        do {
            c = readChar(dis);
        } while (Character.isWhitespace(c));
        // read the word
        do {
            sb.append(c);
            c = readChar(dis);
        } while (!Character.isWhitespace(c));
        return sb.toString();
    }

    /**
     * Reads a single char from the stream.
     *
     * @param dis the stream to read
     * @return the next character on the stream
     * @throws IOException if an error occurs
     */
    private char readChar(DataInputStream dis) throws IOException {
        return (char) dis.readByte();
    }

    /**
     * Swap a 32 bit word.
     *
     * @param val the value to swap
     * @return the swapped value
     */
    private int byteSwap(int val) {
        return ((0xff & (val >> 24)) | (0xff00 & (val >> 8))
                | (0xff0000 & (val << 8)) | (0xff000000 & (val << 24)));
    }

    /**
     * Read an integer from the input stream, byte-swapping as necessary.
     *
     * @param dis the inputstream
     * @return an integer value
     * @throws IOException on error
     */
    protected int readInt(DataInputStream dis) throws IOException {
        if (swap) {
            return Utilities.readLittleEndianInt(dis);
        } else {
            return dis.readInt();
        }
    }

    /**
     * Read a float from the input stream, byte-swapping as necessary.
     *
     * @param dis the inputstream
     * @return a floating pint value
     * @throws IOException on error
     */
    protected float readFloat(DataInputStream dis) throws IOException {
        float val;
        if (swap) {
            val = Utilities.readLittleEndianFloat(dis);
        } else {
            val = dis.readFloat();
        }
        return val;
    }

    // Do we need the method nonZeroFloor??
    /**
     * If a data point is non-zero and below 'floor' make it equal to floor
     * (don't floor zero values though).
     *
     * @param data  the data to floor
     * @param floor the floored value
     */
    protected void nonZeroFloor(float[] data, float floor) {
        for (int i = 0; i < data.length; i++) {
            if (data[i] != 0.0 && data[i] < floor) {
                data[i] = floor;
            }
        }
    }

    /**
     * If a data point is below 'floor' make it equal to floor.
     *
     * @param data  the data to floor
     * @param floor the floored value
     */
    private void floorData(float[] data, float floor) {
        for (int i = 0; i < data.length; i++) {
            if (data[i] < floor) {
                data[i] = floor;
            }
        }
    }

    /**
     * Normalize the given data.
     *
     * @param data the data to normalize
     */
    protected void normalize(float[] data) {
        float sum = 0;
        for (float val : data) {
            sum += val;
        }
        if (sum != 0.0f) {
            for (int i = 0; i < data.length; i++) {
                data[i] = data[i] / sum;
            }
        }
    }

    /**
     * Convert to log math.
     *
     * @param data the data to normalize
     */
    // linearToLog returns a float, so zero values in linear scale
    // should return -Float.MAX_VALUE.
    protected void convertToLogMath(float[] data) {
        for (int i = 0; i < data.length; i++) {
            data[i] = logMath.linearToLog(data[i]);
        }
    }

    /**
     * Reads the given number of floats from the stream and returns them in an
     * array of floats.
     *
     * @param dis  the stream to read data from
     * @param size the number of floats to read
     * @return an array of size float elements
     * @throws IOException if an exception occurs
     */
    protected float[] readFloatArray(DataInputStream dis, int size)
            throws IOException {
        float[] data = new float[size];
        for (int i = 0; i < size; i++) {
            data[i] = readFloat(dis);
        }
        return data;
    }

    /**
     * Loads the sphinx3 densityfile, a set of density arrays are created and placed in the given pool.
     *
     * @param useCDUnits  if true, loads also the context dependent units
     * @param inputStream the open input stream to use
     * @param path        the path to a density file
     * @throws FileNotFoundException if a file cannot be found
     * @throws IOException           if an error occurs while loading the data
     */
    protected void loadHMMPool(boolean useCDUnits, InputStream inputStream, String path)
            throws IOException {
        ExtendedStreamTokenizer est = new ExtendedStreamTokenizer(inputStream, '#', false);

        logger.fine("Loading HMM file from: " + path);

        est.expectString(MODEL_VERSION);

        int numBase = est.getInt("numBase");
        est.expectString("n_base");

        int numTri = est.getInt("numTri");
        est.expectString("n_tri");

        int numStateMap = est.getInt("numStateMap");
        est.expectString("n_state_map");

        int numTiedState = est.getInt("numTiedState");
        est.expectString("n_tied_state");

        int numContextIndependentTiedState = est.getInt("numContextIndependentTiedState");
        est.expectString("n_tied_ci_state");

        int numTiedTransitionMatrices = est.getInt("numTiedTransitionMatrices");
        est.expectString("n_tied_tmat");

        int numStatePerHMM = numStateMap / (numTri + numBase);

        assert numTiedState == mixtureWeightsPool.getFeature(NUM_SENONES, 0);
        assert numTiedTransitionMatrices == matrixPool.size();

        // Load the base phones
        for (int i = 0; i < numBase; i++) {
            String name = est.getString();
            String left = est.getString();
            String right = est.getString();
            String position = est.getString();
            String attribute = est.getString();
            int tmat = est.getInt("tmat");

            int[] stid = new int[numStatePerHMM - 1];

            for (int j = 0; j < numStatePerHMM - 1; j++) {
                stid[j] = est.getInt("j");
                assert stid[j] >= 0 && stid[j] < numContextIndependentTiedState;
            }
            est.expectString("N");

            assert left.equals("-");
            assert right.equals("-");
            assert position.equals("-");
            assert tmat < numTiedTransitionMatrices;

            Unit unit = unitManager.getUnit(name, attribute.equals(FILLER));
            contextIndependentUnits.put(unit.getName(), unit);

            if (logger.isLoggable(Level.FINE)) {
                logger.fine("Loaded " + unit);
            }

            // The first filler
            if (unit.isFiller() && unit.getName().equals(SILENCE_CIPHONE)) {
                unit = UnitManager.SILENCE;
            }

            float[][] transitionMatrix = matrixPool.get(tmat);
            SenoneSequence ss = getSenoneSequence(stid);

            HMM hmm = new SenoneHMM(unit, ss, transitionMatrix, HMMPosition.lookup(position));
            hmmManager.put(hmm);
        }

        // Load the context dependent phones. If the useCDUnits
        // property is false, the CD phones will not be created, but
        // the values still need to be read in from the file.

        String lastUnitName = "";
        Unit lastUnit = null;
        int[] lastStid = null;
        SenoneSequence lastSenoneSequence = null;

        for (int i = 0; i < numTri; i++) {
            String name = est.getString();
            String left = est.getString();
            String right = est.getString();
            String position = est.getString();
            String attribute = est.getString();
            int tmat = est.getInt("tmat");

            int[] stid = new int[numStatePerHMM - 1];

            for (int j = 0; j < numStatePerHMM - 1; j++) {
                stid[j] = est.getInt("j");
                assert stid[j] >= numContextIndependentTiedState &&
                        stid[j] < numTiedState;
            }
            est.expectString("N");

            assert !left.equals("-");
            assert !right.equals("-");
            assert !position.equals("-");
            assert attribute.equals("n/a");
            assert tmat < numTiedTransitionMatrices;

            if (useCDUnits) {
                Unit unit;
                String unitName = (name + ' ' + left + ' ' + right);

                if (unitName.equals(lastUnitName)) {
                    unit = lastUnit;
                } else {
                    Unit[] leftContext = new Unit[1];
                    leftContext[0] = contextIndependentUnits.get(left);

                    Unit[] rightContext = new Unit[1];
                    rightContext[0] = contextIndependentUnits.get(right);

                    Context context = LeftRightContext.get(leftContext,
                            rightContext);
                    unit = unitManager.getUnit(name, false, context);
                }
                lastUnitName = unitName;
                lastUnit = unit;

                if (logger.isLoggable(Level.FINE)) {
                    logger.fine("Loaded " + unit);
                }

                float[][] transitionMatrix = matrixPool.get(tmat);

                SenoneSequence ss = lastSenoneSequence;
                if (ss == null || !sameSenoneSequence(stid, lastStid)) {
                    ss = getSenoneSequence(stid);
                }
                lastSenoneSequence = ss;
                lastStid = stid;

                HMM hmm = new SenoneHMM(unit, ss, transitionMatrix, HMMPosition.lookup(position));
                hmmManager.put(hmm);
            }
        }

        est.close();
    }

    /**
     * Returns true if the given senone sequence IDs are the same.
     *
     * @param ssid1
     * @param ssid2
     * @return true if the given senone sequence IDs are the same, false otherwise
     */
    protected boolean sameSenoneSequence(int[] ssid1, int[] ssid2) {
        if (ssid1.length == ssid2.length) {
            for (int i = 0; i < ssid1.length; i++) {
                if (ssid1[i] != ssid2[i]) {
                    return false;
                }
            }
            return true;
        } else {
            return false;
        }
    }

    /**
     * Gets the senone sequence representing the given senones.
     *
     * @param stateid is the array of senone state ids
     * @return the senone sequence associated with the states
     */
    protected SenoneSequence getSenoneSequence(int[] stateid) {
        Senone[] senones = new Senone[stateid.length];
        for (int i = 0; i < stateid.length; i++) {
            senones[i] = senonePool.get(stateid[i]);
        }
        return new SenoneSequence(senones);
    }

    /**
     * Loads the mixture weights.
     *
     * @param path  the path to the mixture weight file
     * @param floor the minimum mixture weight allowed
     * @return a pool of mixture weights
     * @throws FileNotFoundException if a file cannot be found
     * @throws IOException           if an error occurs while loading the data
     */
    private Pool<float[]> loadMixtureWeightsAscii(String path, float floor)
            throws IOException {
        logger.fine("Loading mixture weights from: " + path);
        InputStream inputStream = getDataStream(path);
        if (inputStream == null) {
            throw new FileNotFoundException("Error trying to read file " + path);
        }

        Pool<float[]> pool = new Pool<float[]>(path);
        ExtendedStreamTokenizer est = new ExtendedStreamTokenizer(inputStream, '#', false);
        est.expectString("mixw");
        int numStates = est.getInt("numStates");
        int numStreams = est.getInt("numStreams");
        int numGaussiansPerState = est.getInt("numGaussiansPerState");
        pool.setFeature(NUM_SENONES, numStates);
        pool.setFeature(NUM_STREAMS, numStreams);
        pool.setFeature(NUM_GAUSSIANS_PER_STATE, numGaussiansPerState);
        for (int i = 0; i < numStates; i++) {
            est.expectString("mixw");
            est.expectString("[" + i);
            est.expectString("0]");
            // float total = est.getFloat("total");
            float[] logMixtureWeight = new float[numGaussiansPerState];
            for (int j = 0; j < numGaussiansPerState; j++) {
                float val = est.getFloat("mixwVal");
                if (val < floor) {
                    val = floor;
                }
                logMixtureWeight[j] = val;
            }
            convertToLogMath(logMixtureWeight);
            pool.put(i, logMixtureWeight);
        }
        est.close();
        return pool;
    }

    /**
     * Loads the mixture weights (Binary).
     *
     * @param path  the path to the mixture weight file
     * @param floor the minimum mixture weight allowed
     * @return a pool of mixture weights
     * @throws FileNotFoundException if a file cannot be found
     * @throws IOException           if an error occurs while loading the data
     */
    private Pool<float[]> loadMixtureWeightsBinary(String path, float floor)
            throws IOException {
        logger.fine("Loading mixture weights from: " + path);

        Properties props = new Properties();

        DataInputStream dis = readS3BinaryHeader(path, props);

        String version = props.getProperty("version");

        if (version == null || !version.equals(MIXW_FILE_VERSION)) {
            throw new IOException("Unsupported version in " + path);
        }

        String checksum = props.getProperty("chksum0");
        boolean doCheckSum = (checksum != null && checksum.equals("yes"));

        Pool<float[]> pool = new Pool<float[]>(path);

        int numStates = readInt(dis);
        int numStreams = readInt(dis);
        int numGaussiansPerState = readInt(dis);
        int numValues = readInt(dis);

        assert numValues == numStates * numStreams * numGaussiansPerState;
        assert numStreams == 1;

        pool.setFeature(NUM_SENONES, numStates);
        pool.setFeature(NUM_STREAMS, numStreams);
        pool.setFeature(NUM_GAUSSIANS_PER_STATE, numGaussiansPerState);

        for (int i = 0; i < numStates; i++) {
            float[] logMixtureWeight = readFloatArray(dis, numGaussiansPerState);
            normalize(logMixtureWeight);
            floorData(logMixtureWeight, floor);
            convertToLogMath(logMixtureWeight);
            pool.put(i, logMixtureWeight);
        }
        dis.close();
        return pool;
    }

    /**
     * Loads the transition matrices.
     *
     * @param path the path to the transitions matrices
     * @return a pool of transition matrices
     * @throws FileNotFoundException if a file cannot be found
     * @throws IOException           if an error occurs while loading the data
     */
    protected Pool<float[][]> loadTransitionMatricesAscii(String path)
            throws IOException {
        logger.fine("Loading transition matrices from: " + path);

        InputStream inputStream = getDataStream(path);
        if (inputStream == null) {
            throw new FileNotFoundException("Error trying to read file " + path);
        }

        Pool<float[][]> pool = new Pool<float[][]>(path);
        ExtendedStreamTokenizer est = new ExtendedStreamTokenizer(inputStream, '#', false);
        est.expectString("tmat");
        int numMatrices = est.getInt("numMatrices");
        int numStates = est.getInt("numStates");
        logger.fine("with " + numMatrices + " and " + numStates
                + " states, in " + (sparseForm ? "sparse" : "dense") + " form");

        // read in the matrices
        for (int i = 0; i < numMatrices; i++) {
            est.expectString("tmat");
            est.expectString("[" + i + ']');
            float[][] tmat = new float[numStates][numStates];
            for (int j = 0; j < numStates; j++) {
                for (int k = 0; k < numStates; k++) {
                    // the last row is just zeros, so we just do
                    // the first (numStates - 1) rows
                    if (j < numStates - 1) {
                        if (sparseForm) {
                            if (k == j || k == j + 1) {
                                tmat[j][k] = est.getFloat("tmat value");
                            }
                        } else {
                            tmat[j][k] = est.getFloat("tmat value");
                        }
                    }
                    tmat[j][k] = logMath.linearToLog(tmat[j][k]);
                    if (logger.isLoggable(Level.FINE)) {
                        logger.fine("tmat j " + j + " k " + k + " tm " + tmat[j][k]);
                    }
                }
            }
            pool.put(i, tmat);
        }
        est.close();
        return pool;
    }

    /**
     * Loads the transition matrices (Binary).
     *
     * @param path the path to the transitions matrices
     * @return a pool of transition matrices
     * @throws FileNotFoundException if a file cannot be found
     * @throws IOException           if an error occurs while loading the data
     */
    protected Pool<float[][]> loadTransitionMatricesBinary(String path)
            throws IOException {
        logger.fine("Loading transition matrices from: " + path);

        Properties props = new Properties();
        DataInputStream dis = readS3BinaryHeader(path, props);

        String version = props.getProperty("version");

        if (version == null || !version.equals(TMAT_FILE_VERSION)) {
            throw new IOException("Unsupported version in " + path);
        }

        String checksum = props.getProperty("chksum0");
        boolean doCheckSum = (checksum != null && checksum.equals("yes"));

        Pool<float[][]> pool = new Pool<float[][]>(path);

        int numMatrices = readInt(dis);
        int numRows = readInt(dis);
        int numStates = readInt(dis);
        int numValues = readInt(dis);

        assert numValues == numStates * numRows * numMatrices;

        for (int i = 0; i < numMatrices; i++) {
            float[][] tmat = new float[numStates][];
            // last row should be zeros
            tmat[numStates - 1] = new float[numStates];
            convertToLogMath(tmat[numStates - 1]);

            for (int j = 0; j < numRows; j++) {
                tmat[j] = readFloatArray(dis, numStates);
                nonZeroFloor(tmat[j], 0f);
                normalize(tmat[j]);
                convertToLogMath(tmat[j]);
            }
            pool.put(i, tmat);
        }
        dis.close();
        return pool;
    }

    /**
     * Loads the transform matrices (Binary).
     *
     * @param path the path to the transform matrix
     * @return a transform matrix
     * @throws java.io.FileNotFoundException if a file cannot be found
     * @throws java.io.IOException           if an error occurs while loading the data
     */
    protected float[][] loadTransformMatrix(String path)
            throws IOException {
        logger.fine("Loading transform matrix from: " + path);

        Properties props = new Properties();

        DataInputStream dis;
        try {
            dis = readS3BinaryHeader(path, props);
        } catch (Exception e) {
            return null;
        }

        String version = props.getProperty("version");

        if (version == null || !version.equals(TRANSFORM_FILE_VERSION)) {
            throw new IOException("Unsupported version in " + path);
        }

        String checksum = props.getProperty("chksum0");
        boolean doCheckSum = (checksum != null && checksum.equals("yes"));

        readInt(dis);
        int numRows = readInt(dis);
        int numValues = readInt(dis);
        int num = readInt(dis);

        assert num == numRows * numValues;

        float[][] result = new float[numRows][];
        for (int i = 0; i < numRows; i++) {
            result[i] = readFloatArray(dis, numValues);
        }
        dis.close();
        return result;
    }

    /**
     * Creates a pool with a single identity matrix in it.
     *
     * @param name the name of the pool
     * @return the pool with the matrix
     */
    private Pool<float[][]> createDummyMatrixPool(String name) {
        Pool<float[][]> pool = new Pool<float[][]>(name);
        float[][] matrix = new float[vectorLength][vectorLength];
        logger.fine("creating dummy matrix pool " + name);
        for (int i = 0; i < vectorLength; i++) {
            for (int j = 0; j < vectorLength; j++) {
                if (i == j) {
                    matrix[i][j] = 1.0F;
                } else {
                    matrix[i][j] = 0.0F;
                }
            }
        }
        pool.put(0, matrix);
        return pool;
    }

    /**
     * Creates a pool with a single zero vector in it.
     *
     * @param name the name of the pool
     * @return the pool with the vector
     */
    private Pool<float[]> createDummyVectorPool(String name) {
        logger.fine("creating dummy vector pool " + name);
        Pool<float[]> pool = new Pool<float[]>(name);
        float[] vector = new float[vectorLength];
        for (int i = 0; i < vectorLength; i++) {
            vector[i] = 0.0f;
        }
        pool.put(0, vector);
        return pool;
    }

    @Override
    public Pool<float[]> getMeansPool() {
        return meansPool;
    }

    @Override
    public Pool<float[][]> getMeansTransformationMatrixPool() {
        return meanTransformationMatrixPool;
    }

    @Override
    public Pool<float[]> getMeansTransformationVectorPool() {
        return meanTransformationVectorPool;
    }

    @Override
    public Pool<float[]> getVariancePool() {
        return variancePool;
    }

    @Override
    public Pool<float[][]> getVarianceTransformationMatrixPool() {
        return varianceTransformationMatrixPool;
    }

    @Override
    public Pool<float[]> getVarianceTransformationVectorPool() {
        return varianceTransformationVectorPool;
    }

    @Override
    public Pool<float[]> getMixtureWeightPool() {
        return mixtureWeightsPool;
    }

    @Override
    public Pool<float[][]> getTransitionMatrixPool() {
        return matrixPool;
    }

    @Override
    public float[][] getTransformMatrix() {
        return transformMatrix;
    }

    @Override
    public Pool<Senone> getSenonePool() {
        return senonePool;
    }

    @Override
    public int getLeftContextSize() {
        return CONTEXT_SIZE;
    }

    @Override
    public int getRightContextSize() {
        return CONTEXT_SIZE;
    }

    @Override
    public HMMManager getHMMManager() {
        return hmmManager;
    }

    @Override
    public void logInfo() {
        logger.info("Sphinx3Loader");
        meansPool.logInfo(logger);
        variancePool.logInfo(logger);
        matrixPool.logInfo(logger);
        senonePool.logInfo(logger);
        meanTransformationMatrixPool.logInfo(logger);
        meanTransformationVectorPool.logInfo(logger);
        varianceTransformationMatrixPool.logInfo(logger);
        varianceTransformationVectorPool.logInfo(logger);
        mixtureWeightsPool.logInfo(logger);
        senonePool.logInfo(logger);
        logger.info("Context Independent Unit Entries: " + contextIndependentUnits.size());
        hmmManager.logInfo(logger);
    }
}
